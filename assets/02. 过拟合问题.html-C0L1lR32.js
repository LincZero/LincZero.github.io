import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as i,c as s,e as t,a,b as e}from"./app-BP7mptqa.js";const n="/assets/image-20220907112455929-DWIgU8oB.png",r="/assets/image-20220907112911382-Dn-F-SJ-.png",c="/assets/image-20220907125551876-QB_f9JeJ.png",p={},o=t('<h1 id="吴恩达机器学习" tabindex="-1"><a class="header-anchor" href="#吴恩达机器学习"><span>吴恩达机器学习</span></a></h1><h1 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h1><h1 id="其他补充" tabindex="-1"><a class="header-anchor" href="#其他补充"><span>其他补充</span></a></h1><h2 id="过拟合问题-overfit" tabindex="-1"><a class="header-anchor" href="#过拟合问题-overfit"><span>过拟合问题（Overfit）</span></a></h2><h3 id="过拟合问题" tabindex="-1"><a class="header-anchor" href="#过拟合问题"><span>过拟合问题</span></a></h3><p>概念与总结</p><ul><li><p>若拟合过低：我们称为 <strong>欠拟合（Underfit）</strong>，也可以用另一个术语描述： <strong>高偏差（High Bias）</strong></p><p>例如你通常不能用一个线性回归模型或二阶多项式回归来拟合一个多项式回归模型</p></li><li><p>若拟合过高：我们称为 <strong>过拟合（Overfit）</strong>，也可以用另一个术语描述：<strong>高方差（High Variance）</strong>。 或者称为 有<strong>泛化误差</strong>（Generalization Error）</p><p>例如你通常不能用一个非常高阶的多项式回归模型来拟合数据</p></li></ul><p>【用图来说明什么是过拟合问题】</p><p>这里用一个回归模型来举例： <em>（注意：图片中x的上标应该是指第几个特征，而不是幂，因为他的下标是用来标注第几条数据的）</em></p><figure><img src="'+n+'" alt="image-20220907112455929" tabindex="0" loading="lazy"><figcaption>image-20220907112455929</figcaption></figure><p>这里再用一个分类需求的模型来举例：</p><figure><img src="'+r+'" alt="image-20220907112911382" tabindex="0" loading="lazy"><figcaption>image-20220907112911382</figcaption></figure><h3 id="解决过拟合-三种方法" tabindex="-1"><a class="header-anchor" href="#解决过拟合-三种方法"><span>解决过拟合（三种方法）</span></a></h3><p>解决方法</p>',14),m=a("ul",null,[a("li",null,[a("p",null,"① 更多的训练数据（Collect more data）")]),a("li",null,[a("p",null,"② 使用更少的特征（Feature Selection）"),a("p",null,"不使用太高阶的多项式回归来拟合也是此类 比如本来需要用房屋的100个参数来预测，可以去除一些不必要的")]),a("li",null,[a("p",null,"③ 正则化（Regularization，即 Reduce size of parameters）"),a("p",null,[e("与方法二相类似的，只是不会去剔除特征，而是会将该特征的权重"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msub",null,[a("mi",null,"w"),a("mi",null,"i")])]),a("annotation",{encoding:"application/x-tex"},"w_i")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.3117em"}},[a("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mathnormal mtight"},"i")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])])])])]),e("降至极低。减少过拟合的程度")])])],-1),h=t('<p>比较方法二和方法三： <em>（注意：图片中x的上标应该是指第几个特征，而不是幂，因为他的下标是用来标注第几条数据的）</em></p><figure><img src="'+c+'" alt="image-20220907125551876" tabindex="0" loading="lazy"><figcaption>image-20220907125551876</figcaption></figure><h3 id="正则化-regularization" tabindex="-1"><a class="header-anchor" href="#正则化-regularization"><span>正则化（Regularization）</span></a></h3><h4 id="正则化方法" tabindex="-1"><a class="header-anchor" href="#正则化方法"><span>正则化方法</span></a></h4><p>以回归模型为例：</p><p class="katex-block"><span class="katex-error" title="ParseError: KaTeX parse error: Unexpected end of input in a macro argument, expected &#39;}&#39; at position 173: …{\\color{\\orange}̲\\frac{1}{2 m} \\…" style="color:#cc0000;"> ~ \\begin{align} 未正则化代价函数：J(\\vec w,b)=&amp;\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(f_{\\vec w,b}\\left(x_{i}\\right)-y_{i}\\right)^{2}\\\\ 正则化代价函数：J(\\vec w,b)=&amp;{\\color{\\orange}\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(f_{\\vec w,b}\\left(x_{i}\\right)-y_{i}\\right)^{2}} +{\\color{red}\\frac\\lambda{2m}\\sum^n_{j=1}w_j^2 +\\frac\\lambda{2m}b^2} \\end{align}\\\\ ~\\\\ </span></p><p>其中</p>',7),g=a("ul",null,[a("li",null,"m 是训练数据的数量、n 是特征的数量"),a("li",null,[a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"λ")]),a("annotation",{encoding:"application/x-tex"},"\\lambda")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6944em"}}),a("span",{class:"mord mathnormal"},"λ")])])]),e("叫 "),a("strong",null,"正则化参数"),e("（regularizationparameter），且"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"λ"),a("mo",null,">"),a("mn",null,"0")]),a("annotation",{encoding:"application/x-tex"},"\\lambda>0")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7335em","vertical-align":"-0.0391em"}}),a("span",{class:"mord mathnormal"},"λ"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},">"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6444em"}}),a("span",{class:"mord"},"0")])])]),a("ul",null,[a("li",null,[a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"λ")]),a("annotation",{encoding:"application/x-tex"},"\\lambda")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6944em"}}),a("span",{class:"mord mathnormal"},"λ")])])]),e("的值设置越大，正则化代价函数右侧的权重就越高，w就越小。归一化程度越高")]),a("li",null,[a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"λ")]),a("annotation",{encoding:"application/x-tex"},"\\lambda")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6944em"}}),a("span",{class:"mord mathnormal"},"λ")])])]),e("的值设置越小，正则化代价函数左侧的权重就越高，w就越大。拟合程度越高、越约容易过拟合")])])])],-1),d=t('<h4 id="用于线性回归的正则方法" tabindex="-1"><a class="header-anchor" href="#用于线性回归的正则方法"><span>用于线性回归的正则方法</span></a></h4><p>未正则化的梯度下降</p><p class="katex-block"><span class="katex-error" title="ParseError: KaTeX parse error: Unexpected end of input in a macro argument, expected &#39;}&#39; at position 42: …{\\color{\\orange}̲\\frac{1}{2 m} \\…" style="color:#cc0000;"> 未正则化代价函数：\\\\ J(\\vec w,b)={\\color{\\orange}\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(f_{\\vec w,b}\\left(x_{i}\\right)-y_{i}\\right)^{2}}\\\\~\\\\ 未正则化的梯度下降：\\\\ \\begin{align} w_j:=&amp;w_j-\\alpha\\frac\\partial{\\partial w_j}J(\\vec w,b) &amp;&amp;=w_j-\\alpha\\frac 1m\\sum_{i-1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)x_{ij}\\\\ b:=&amp;b-\\alpha\\frac\\partial{\\partial b}J(\\vec w,b) &amp;&amp;=b-\\alpha\\frac 1m\\sum_{i-1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)\\\\ \\end{align} </span></p><p>正则化后的梯度下降</p><p class="katex-block"><span class="katex-error" title="ParseError: KaTeX parse error: Unexpected end of input in a macro argument, expected &#39;}&#39; at position 41: …{\\color{\\orange}̲\\frac{1}{2 m} \\…" style="color:#cc0000;"> 正则化代价函数：\\\\ J(\\vec w,b)={\\color{\\orange}\\frac{1}{2 m} \\sum_{i=1}^{m}\\left(f_{\\vec w,b}\\left(x_{i}\\right)-y_{i}\\right)^{2}} +{\\color{red}\\frac\\lambda{2m}\\sum^n_{j=1}w_j^2}\\\\~\\\\ 梯度下降：\\\\ \\begin{align} w_j:=&amp;w_j-\\alpha\\frac\\partial{\\partial w_j}J(\\vec w,b) &amp;&amp;=w_j-\\alpha[\\frac 1m\\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)x_{ij}+{\\color{red}\\frac\\lambda m w_j}]\\\\ &amp;&amp;&amp;=w_j-\\alpha\\frac\\lambda m w_j-\\alpha\\frac1m \\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)x_{ij}\\\\ &amp;&amp;&amp;={\\color{red}w_j(1-\\alpha\\frac\\lambda m)}-\\alpha\\frac1m \\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)x_{ij}\\\\ b:=&amp;b-\\alpha\\frac\\partial{\\partial b}J(\\vec w,b) &amp;&amp;=b-\\alpha[\\frac 1m\\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)]\\\\ \\end{align} </span></p><h4 id="用于逻辑回归的正则方法" tabindex="-1"><a class="header-anchor" href="#用于逻辑回归的正则方法"><span>用于逻辑回归的正则方法</span></a></h4><p>逻辑回归的梯度下降“看起来”是和线性回归差不多的，正则化了也是</p><p>正则化后的梯度下降</p><p class="katex-block"><span class="katex-error" title="ParseError: KaTeX parse error: Unexpected end of input in a macro argument, expected &#39;}&#39; at position 41: …{\\color{\\orange}̲\\frac{1}{m} \\su…" style="color:#cc0000;"> 正则化代价函数：\\\\ J(\\vec w,b)={\\color{\\orange}\\frac{1}{m} \\sum_{i=1}^{m} \\left[y_i\\log\\left(f_{\\vec w,b}(x_i)\\right)+(1-y_i)\\log\\left(1-f_{\\vec w,b}(x_i)\\right)\\right]} +{\\color{red}\\frac\\lambda{2m}\\sum^n_{j=1}w_j^2}\\\\~\\\\ 梯度下降：\\\\ \\begin{align} w_j:=&amp;w_j-\\alpha\\frac\\partial{\\partial w_j}J(\\vec w,b) &amp;&amp;=w_j-\\alpha[\\frac 1m\\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)x_{ij}+{\\color{red}\\frac\\lambda m w_j}]\\\\ &amp;&amp;&amp;={\\color{red}w_j(1-\\alpha\\frac\\lambda m)}-\\alpha\\frac1m \\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)x_{ij}\\\\ b:=&amp;b-\\alpha\\frac\\partial{\\partial b}J(\\vec w,b) &amp;&amp;=b-\\alpha[\\frac 1m\\sum_{i=1}^m(f_{\\vec w,b}(\\vec x_i)-y_i)]\\\\ \\end{align} </span></p><h4 id="程序示例" tabindex="-1"><a class="header-anchor" href="#程序示例"><span>程序示例</span></a></h4><p>见神经网络一章的优化一节</p>',11),_=[o,m,h,g,d];function u(f,b){return i(),s("div",null,_)}const w=l(p,[["render",u],["__file","02. 过拟合问题.html.vue"]]),v=JSON.parse('{"path":"/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/01.%20%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01.%20%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02.%20%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98.html","title":"吴恩达机器学习","lang":"zh-CN","frontmatter":{"description":"吴恩达机器学习 目录 其他补充 过拟合问题（Overfit） 过拟合问题 概念与总结 若拟合过低：我们称为 欠拟合（Underfit），也可以用另一个术语描述： 高偏差（High Bias） 例如你通常不能用一个线性回归模型或二阶多项式回归来拟合一个多项式回归模型 若拟合过高：我们称为 过拟合（Overfit），也可以用另一个术语描述：高方差（High...","head":[["meta",{"property":"og:url","content":"http://192.168.0.101:8080/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/01.%20%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01.%20%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02.%20%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"吴恩达机器学习"}],["meta",{"property":"og:description","content":"吴恩达机器学习 目录 其他补充 过拟合问题（Overfit） 过拟合问题 概念与总结 若拟合过低：我们称为 欠拟合（Underfit），也可以用另一个术语描述： 高偏差（High Bias） 例如你通常不能用一个线性回归模型或二阶多项式回归来拟合一个多项式回归模型 若拟合过高：我们称为 过拟合（Overfit），也可以用另一个术语描述：高方差（High..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"LincZero"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"吴恩达机器学习\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"吴恩达机器学习","slug":"吴恩达机器学习","link":"#吴恩达机器学习","children":[]},{"level":1,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":1,"title":"其他补充","slug":"其他补充","link":"#其他补充","children":[{"level":2,"title":"过拟合问题（Overfit）","slug":"过拟合问题-overfit","link":"#过拟合问题-overfit","children":[{"level":3,"title":"过拟合问题","slug":"过拟合问题","link":"#过拟合问题","children":[]},{"level":3,"title":"解决过拟合（三种方法）","slug":"解决过拟合-三种方法","link":"#解决过拟合-三种方法","children":[]},{"level":3,"title":"正则化（Regularization）","slug":"正则化-regularization","link":"#正则化-regularization","children":[{"level":4,"title":"正则化方法","slug":"正则化方法","link":"#正则化方法","children":[]},{"level":4,"title":"用于线性回归的正则方法","slug":"用于线性回归的正则方法","link":"#用于线性回归的正则方法","children":[]},{"level":4,"title":"用于逻辑回归的正则方法","slug":"用于逻辑回归的正则方法","link":"#用于逻辑回归的正则方法","children":[]},{"level":4,"title":"程序示例","slug":"程序示例","link":"#程序示例","children":[]}]}]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.83,"words":1149},"filePathRelative":"MdNote_Public/01. 设计开发与数据生产/Develop/04. Project/Type/Artificial_Intelligence/线性型/01. 吴恩达 机器学习/01. 监督机器学习/02. 过拟合问题.md","autoDesc":true}');export{w as comp,v as data};
