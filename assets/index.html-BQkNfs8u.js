import{_ as e,c as o,e as r,o as n}from"./app-Dwsnbiv5.js";const a="/assets/controlnet_example-AmY5Epj7.png",l="/assets/input_scribble_example-BCpn9ePR.png",p="/assets/shark_depthmap-C1GR7Nlk.png",s="/assets/depth_t2i_adapter-CXEjvGnr.png",i="/assets/depth_controlnet-DXJf4cw9.png",c="/assets/pose_worship-B77nfsO4.png",m="/assets/2_pass_pose_worship-CekpeLvz.png",h="/assets/mixing_controlnets-DTqIWD0P.png",d="/assets/pose_present-Co7Unkiz.png",g="/assets/house_scribble-CqvsQpJ6.png",_={};function f(C,t){return n(),o("div",null,t[0]||(t[0]=[r('<h1 id="controlnet-和-t2i-adapter-示例" tabindex="-1"><a class="header-anchor" href="#controlnet-和-t2i-adapter-示例"><span>ControlNet 和 T2I-Adapter 示例</span></a></h1><p>请注意，在这些示例中，原始图像直接传递到 ControlNet/T2I 适配器。</p><p>如果您想要获得良好的结果，每个 ControlNet/T2I 适配器都需要将传递给它的图像设置为特定格式，例如深度图、精明图等，具体取决于特定模型。</p><p>ControlNetApply 节点不会将常规图像转换为深度图、精明图等。您必须单独执行此操作，或使用节点对图像进行预处理，您可以在此处找到：<a href="https://github.com/Fannovel16/comfy_controlnet_preprocessors" target="_blank" rel="noopener noreferrer">此处</a></p><p>您可以在此处找到最新的 controlnet 模型文件：<a href="https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main" target="_blank" rel="noopener noreferrer">原始版本</a>或<a href="https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/tree/main" target="_blank" rel="noopener noreferrer">较小的 fp16 safetensors 版本</a></p><p>对于 SDXL，stable.ai 已发布 Control Loras，您可以<a href="https://huggingface.co/stabilityai/control-lora/tree/main/control-LoRAs-rank256" target="_blank" rel="noopener noreferrer">在这里（排名 256）</a>或<a href="https://huggingface.co/stabilityai/control-lora/tree/main/control-LoRAs-rank128" target="_blank" rel="noopener noreferrer">这里（排名 128）</a>找到。它们的使用方式与常规 ControlNet 模型文件完全相同（将它们放在同一目录中）。</p><p>ControlNet 模型文件位于 ComfyUI/models/controlnet 目录中。</p><h3 id="涂鸦-controlnet" tabindex="-1"><a class="header-anchor" href="#涂鸦-controlnet"><span>涂鸦 ControlNet</span></a></h3><p>这是一个如何使用控制网的简单示例，此示例使用 scribble 控制网和 AnythingV3 模型。您可以在<a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" rel="noopener noreferrer">ComfyUI</a>中加载此图像以获取完整的工作流程。</p><p><img src="'+a+'" alt="Example" loading="lazy"></p><p>Here is the input image I used for this workflow:</p><img src="'+l+'" width="256"><h3 id="【比较】t2i-adapter-和-controlnets" tabindex="-1"><a class="header-anchor" href="#【比较】t2i-adapter-和-controlnets"><span>【比较】T2I-Adapter 和 ControlNets</span></a></h3><p>T2I 适配器比 ControlNets 效率高得多，因此我强烈推荐它们。ControlNets 会显著降低生成速度，而 T2I 适配器对生成速度几乎没有任何负面影响。</p><p>在 ControlNets 中，ControlNet 模型每次迭代运行一次。对于 T2I-Adapter，该模型总共运行一次。</p><p>T2I-Adapters 的使用方式与 ComfyUI 中的 ControlNets 相同：使用 ControlNetLoader 节点。</p><p><a href="https://commons.wikimedia.org/wiki/File:Stereogram_Tut_Shark_Depthmap.png" target="_blank" rel="noopener noreferrer">这是本示例源</a>中将使用的输入图像：</p><img src="'+p+'" width="512"><p>深度 T2I 适配器的使用方法如下：</p><p><img src="'+s+'" alt="Example" loading="lazy"></p><p>以下是深度控制网的使用方法。请注意，此示例使用 DiffControlNetLoader 节点，因为所使用的控制网是差异控制网。差异控制网需要正确加载模型的权重。DiffControlNetLoader 节点还可用于加载常规控制网模型。加载常规控制网模型时，其行为与 ControlNetLoader 节点相同。</p><p><img src="'+i+'" alt="Example" loading="lazy"></p><p>您可以在<a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" rel="noopener noreferrer">ComfyUI</a>中加载这些图像以获得完整的工作流程。</p><h3 id="姿势-controlnet" tabindex="-1"><a class="header-anchor" href="#姿势-controlnet"><span>姿势 ControlNet</span></a></h3><p>这是本示例中将使用的输入图像：</p><p><img src="'+c+'" alt="Example" loading="lazy"></p><p>下面是一个示例，第一次使用带有控制网的 AnythingV3，第二次使用不带控制网的 AOM3A3（深渊橙色混合 3）并使用它们的 VAE。</p><p><img src="'+m+'" alt="Example" loading="lazy"></p><p><a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" rel="noopener noreferrer">您可以在ComfyUI</a>中加载此图像以获取完整的工作流程。</p><h3 id="混合-controlnets" tabindex="-1"><a class="header-anchor" href="#混合-controlnets"><span>混合 ControlNets</span></a></h3><p>可以像这样应用多个 ControlNet 和 T2I 适配器并产生有趣的结果：</p><p><img src="'+h+'" alt="Example" loading="lazy"></p><p><a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" rel="noopener noreferrer">您可以在ComfyUI</a>中加载此图像以获取完整的工作流程。</p><p>输入图像：</p><p><img src="'+d+'" width="256"><span>        </span><img src="'+g+'" width="256"></p>',35)]))}const N=e(_,[["render",f],["__file","index.html.vue"]]),u=JSON.parse('{"path":"/MdNote_Other/ComfyUI_examples/controlnet/","title":"ControlNet 和 T2I-Adapter 示例","lang":"zh-CN","frontmatter":{"description":"ControlNet 和 T2I-Adapter 示例 请注意，在这些示例中，原始图像直接传递到 ControlNet/T2I 适配器。 如果您想要获得良好的结果，每个 ControlNet/T2I 适配器都需要将传递给它的图像设置为特定格式，例如深度图、精明图等，具体取决于特定模型。 ControlNetApply 节点不会将常规图像转换为深度图、精...","head":[["meta",{"property":"og:url","content":"https://LincZero.github.io/MdNote_Other/ComfyUI_examples/controlnet/"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"ControlNet 和 T2I-Adapter 示例"}],["meta",{"property":"og:description","content":"ControlNet 和 T2I-Adapter 示例 请注意，在这些示例中，原始图像直接传递到 ControlNet/T2I 适配器。 如果您想要获得良好的结果，每个 ControlNet/T2I 适配器都需要将传递给它的图像设置为特定格式，例如深度图、精明图等，具体取决于特定模型。 ControlNetApply 节点不会将常规图像转换为深度图、精..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ControlNet 和 T2I-Adapter 示例\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"ControlNet 和 T2I-Adapter 示例","slug":"controlnet-和-t2i-adapter-示例","link":"#controlnet-和-t2i-adapter-示例","children":[{"level":3,"title":"涂鸦 ControlNet","slug":"涂鸦-controlnet","link":"#涂鸦-controlnet","children":[]},{"level":3,"title":"【比较】T2I-Adapter 和 ControlNets","slug":"【比较】t2i-adapter-和-controlnets","link":"#【比较】t2i-adapter-和-controlnets","children":[]},{"level":3,"title":"姿势 ControlNet","slug":"姿势-controlnet","link":"#姿势-controlnet","children":[]},{"level":3,"title":"混合 ControlNets","slug":"混合-controlnets","link":"#混合-controlnets","children":[]}]}],"git":{},"readingTime":{"minutes":2.48,"words":745},"filePathRelative":"MdNote_Other/ComfyUI_examples/controlnet/README.md","excerpt":"\\n<p>请注意，在这些示例中，原始图像直接传递到 ControlNet/T2I 适配器。</p>\\n<p>如果您想要获得良好的结果，每个 ControlNet/T2I 适配器都需要将传递给它的图像设置为特定格式，例如深度图、精明图等，具体取决于特定模型。</p>\\n<p>ControlNetApply 节点不会将常规图像转换为深度图、精明图等。您必须单独执行此操作，或使用节点对图像进行预处理，您可以在此处找到：<a href=\\"https://github.com/Fannovel16/comfy_controlnet_preprocessors\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">此处</a></p>","autoDesc":true,"bioChainData":{"outlink":[],"backlink":[],"localMap":{"nodes":[{"id":"MdNote_Other/ComfyUI_examples/controlnet/README.md","value":{"title":"ComfyUI_examples/","path":"MdNote_Other/ComfyUI_examples/controlnet/README.md","outlink":[],"backlink":[]}}],"links":[]}}}');export{N as comp,u as data};
