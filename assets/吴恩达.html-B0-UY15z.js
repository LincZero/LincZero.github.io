import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as e,c as p,a,b as n,e as s}from"./app-Bh75ISgc.js";const o={},l=a('<h1 id="tensorflow" tabindex="-1"><a class="header-anchor" href="#tensorflow"><span>TensorFlow</span></a></h1><h1 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h1><h1 id="吴恩达深度学习视频中的一些杂记" tabindex="-1"><a class="header-anchor" href="#吴恩达深度学习视频中的一些杂记"><span>吴恩达深度学习视频中的一些杂记</span></a></h1><p><strong>TensorFlow</strong>很强大。你只需说明如何计算损失函数，它就能求导。而且用一两行代码就能运用梯度优化器，Adam优化器或者其他优化器。</p><p>（注意区别TensorFlow和Transformer，有点像，但一个是python包一个是模型）</p><p>举个例子：</p>',6),c=n("p",null,[n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"J"),n("mo",{stretchy:"false"},"("),n("mi",null,"w"),n("mo",{stretchy:"false"},")"),n("mo",null,"="),n("msup",null,[n("mi",null,"w"),n("mn",null,"2")]),n("mo",null,"−"),n("mn",null,"10"),n("mi",null,"w"),n("mo",null,"+"),n("mn",null,"25")]),n("annotation",{encoding:"application/x-tex"},"J(w)= w^{2}-10w+25")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J"),n("span",{class:"mopen"},"("),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"mclose"},")"),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.8974em","vertical-align":"-0.0833em"}}),n("span",{class:"mord"},[n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.8141em"}},[n("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])])]),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),n("span",{class:"mord"},"10"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"+"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6444em"}}),n("span",{class:"mord"},"25")])])]),s("，这就是损失函数，你通过化简该函数为"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("msup",null,[n("mrow",null,[n("mo",{stretchy:"false"},"("),n("mi",null,"w"),n("mo",null,"−"),n("mn",null,"5"),n("mo",{stretchy:"false"},")")]),n("mn",null,"2")])]),n("annotation",{encoding:"application/x-tex"},"{(w -5)}^{2}")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1.204em","vertical-align":"-0.25em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},[n("span",{class:"mopen"},"("),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mord"},"5"),n("span",{class:"mclose"},")")]),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.954em"}},[n("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])])])])])]),s("，得知最小值是5。但我们来看一下怎样用TensorFlow将其最小化。")],-1),i=a(`<h2 id="最小化损失函数" tabindex="-1"><a class="header-anchor" href="#最小化损失函数"><span>最小化损失函数</span></a></h2><p>在Jupyter notebook中运行以下Python代码</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># 导入TensorFlow</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token comment"># 接下来，让我们定义参数w</span>
<span class="token comment"># 【注意】在TensorFlow中，你要用tf.Variable()来定义我们想要优化的参数。一旦w被称为TensorFlow变量</span>
w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数：J=w^2-10w+25</span>
cost <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span>tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token operator">-</span> <span class="token number">10.</span><span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">25</span><span class="token punctuation">)</span>
<span class="token comment"># 定义学习率为0.01，目标是最小化损失</span>
train <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDescentOptimizer<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>

<span class="token comment"># 最后下面的几行是惯用表达式:</span>
init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
session <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 这样就开启了一个TensorFlow session。</span>
session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span> <span class="token comment"># 来初始化全局变量。</span>

<span class="token comment"># 然后让TensorFlow评估一个变量，我们要用到：</span>
<span class="token comment"># session.run将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以session.run(w)评估了w，让我：：</span>
session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span>

<span class="token comment"># ——————————————————————————————————————————————————————————————————————————</span>

<span class="token comment"># 评估w等于0，因为我们什么都还没运行</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>  	<span class="token comment"># 0.0</span>

<span class="token comment"># 运行一步梯度下降法</span>
session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>	<span class="token comment"># 0.1</span>

<span class="token comment"># 迭代运行梯度下降1000次</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>	<span class="token comment"># 4.99999，与最优解5很接近了</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="添加训练数据" tabindex="-1"><a class="header-anchor" href="#添加训练数据"><span>添加训练数据</span></a></h2>`,4),u=n("p",null,[s("那么如何把训练数据"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"x")]),n("annotation",{encoding:"application/x-tex"},"x")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.4306em"}}),n("span",{class:"mord mathnormal"},"x")])])]),s("加入TensorFlow程序呢？")],-1),r=a(`<div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>coefficient <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">25.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>			<span class="token comment"># 这就是我们要接入x的数据</span>

w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>				<span class="token comment"># X为[3,1]数组。这个placeholder函数告诉TensorFlow，你稍后会为x提供数值。</span>

<span class="token comment"># cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)</span>
<span class="token comment"># cost = w**2-10*w+25</span>
cost <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>w<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>w <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>			<span class="token comment"># x为二次函数的参数</span>

train <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDescentOptimizer<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>

init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
session <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 0.0</span>

session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>coefficients<span class="token punctuation">}</span><span class="token punctuation">)</span>		<span class="token comment"># feed_dict设置我们要接入x的数据</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 0.1</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>coefficients<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 4.99999</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>现在如果你想改变这个二次函数的系数，也是一样的</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># 假设你把</span>
coefficient <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">25.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 改成</span>
coefficient <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">20.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">100.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,3),m=n("p",null,[s("现在这个函数就变成了"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("msup",null,[n("mrow",null,[n("mo",{stretchy:"false"},"("),n("mi",null,"w"),n("mo",null,"−"),n("mn",null,"10"),n("mo",{stretchy:"false"},")")]),n("mn",null,"2")])]),n("annotation",{encoding:"application/x-tex"},"{(w -10)}^{2}")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1.204em","vertical-align":"-0.25em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},[n("span",{class:"mopen"},"("),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mord"},"10"),n("span",{class:"mclose"},")")]),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.954em"}},[n("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])])])])])]),s("，如果我重新运行，希望我得到的使"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("msup",null,[n("mrow",null,[n("mo",{stretchy:"false"},"("),n("mi",null,"w"),n("mo",null,"−"),n("mn",null,"10"),n("mo",{stretchy:"false"},")")]),n("mn",null,"2")])]),n("annotation",{encoding:"application/x-tex"},"{(w -10)}^{2}")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1.204em","vertical-align":"-0.25em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},[n("span",{class:"mopen"},"("),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mord"},"10"),n("span",{class:"mclose"},")")]),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.954em"}},[n("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])])])])])]),s("最小化的"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"w")]),n("annotation",{encoding:"application/x-tex"},"w")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.4306em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")])])]),s("值为10 在梯度下降1000次迭代之后，我们得到9.99998，接近最优解10")],-1),d=a(`<h2 id="更精简的写法" tabindex="-1"><a class="header-anchor" href="#更精简的写法"><span>更精简的写法</span></a></h2><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">25.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">training</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
        x：训练数据
        w：TensorFlow变量
        optimizer：最优化算法
    &quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">cost_fn</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>w<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>w <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost_fn<span class="token punctuation">,</span> <span class="token punctuation">[</span>w<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> w

w <span class="token operator">=</span> training<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="一些补充" tabindex="-1"><a class="header-anchor" href="#一些补充"><span>一些补充</span></a></h2><h3 id="补充-运算符号问题" tabindex="-1"><a class="header-anchor" href="#补充-运算符号问题"><span>补充：运算符号问题</span></a></h3><p>使用这些<code>add</code>和<code>multiply</code>之类的函数。TensorFlow知道如何对<code>add</code>和<code>mutiply</code>，还有其它函数求导，这就是为什么你只需基本实现前向传播，它能弄明白如何做反向传播和梯度计算，因为它已经内置在<code>add</code>，<code>multiply</code>和平方函数中。</p>`,5),k=n("p",null,[s("要是觉得这种写法不好看的话，TensorFlow其实还重载了一般的加减运算等等，因此你也可以把"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"c"),n("mi",null,"o"),n("mi",null,"s"),n("mi",null,"t")]),n("annotation",{encoding:"application/x-tex"},"cost")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6151em"}}),n("span",{class:"mord mathnormal"},"cos"),n("span",{class:"mord mathnormal"},"t")])])]),s("写成更好看的形式")],-1),h=a(`<div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)	# 旧写法</span>
cost <span class="token operator">=</span> w<span class="token operator">**</span><span class="token number">2</span><span class="token operator">-</span><span class="token number">10</span><span class="token operator">*</span>w<span class="token operator">+</span><span class="token number">25</span>										<span class="token comment"># 新写法，被运算符重载支持</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="补充-placeholder的好处" tabindex="-1"><a class="header-anchor" href="#补充-placeholder的好处"><span>补充：placeholder的好处</span></a></h3><p>TensorFlow中的<strong>placeholder</strong>是一个你之后会赋值的变量。 当你运行训练迭代，用<code>feed_dict</code>来让<code>x=coefficients</code>，把训练数据加入损失方程</p><p>如果你在做<strong>mini-batch</strong>梯度下降，你需要在每次迭代时插入不同的mini-batch</p><h3 id="补充-with写法" tabindex="-1"><a class="header-anchor" href="#补充-with写法"><span>补充：with写法</span></a></h3><p>还有最后一点我想提一下，</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@Note</span>：
<span class="token comment"># 下面这三行，在TensorFlow里是符合表达习惯的</span>
session <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 有些程序员会用另一种写法，作用基本上是一样的</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> session<span class="token punctuation">:</span>
    session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
<span class="token comment"># 作用一样，但Python中的with命令更方便清理，以防在执行这个内循环时出现错误或例外</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="补充-换最佳化算法" tabindex="-1"><a class="header-anchor" href="#补充-换最佳化算法"><span>补充：换最佳化算法</span></a></h3><p>在编程框架中你可以用一行代码做很多事情， 例如，你不想用梯度下降法，而是想用<strong>Adam</strong>优化器，你只要改变这行代码： <code>train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)</code>， 就能很快换掉它，换成更好的优化算法。所有现代深度学习编程框架都支持这样的功能，让你很容易就能编写复杂的神经网络。</p><h2 id="tensorflow的一些原理-计算图" tabindex="-1"><a class="header-anchor" href="#tensorflow的一些原理-计算图"><span>TensorFlow的一些原理（计算图）</span></a></h2><p>TensorFlow程序的<strong>核心</strong>是计算损失函数，然后TensorFlow自动计算出导数，以及如何最小化损失</p><p><code>cost =x[0][0]*w**2 +x[1][0]*w + x[2][0]</code></p><p>上面这个代码所做的就是让TensorFlow建立计算图，得到损失函数</p><p>（我看不懂了，而且这里视频好像有一部分被删了，没有看到他说TensorFlow的计算图怎么样）</p><p>前向函数和反向函数的处理</p><blockquote><p>TensorFlow的优点在于，通过用这个计算损失，计算图基本实现前向传播。 TensorFlow已经内置了所有必要的反向函数，回忆一下训练深度神经网络时的<strong>一组前向函数和一组反向函数</strong>，而像TensorFlow之类的编程框架已经内置了必要的反向函数，这也是为什么通过内置函数来计算前向函数，它也能自动用反向函数来实现反向传播，即便函数非常复杂，再帮你计算导数，这就是为什么你不需要明确实现反向传播，这是编程框架能帮你变得高效的原因之一。</p></blockquote><p>TensorFlow的计算图</p>`,17),v=n("blockquote",null,[n("p",null,[s("如果你看TensorFlow的使用说明，我只是指出TensorFlow的说明用了一套和我不太一样的符号来画计算图，它用了"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"x"),n("mo",{stretchy:"false"},"["),n("mn",null,"0"),n("mo",{stretchy:"false"},"]"),n("mo",{stretchy:"false"},"["),n("mn",null,"0"),n("mo",{stretchy:"false"},"]")]),n("annotation",{encoding:"application/x-tex"},"x[0][0]")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),n("span",{class:"mord mathnormal"},"x"),n("span",{class:"mopen"},"["),n("span",{class:"mord"},"0"),n("span",{class:"mclose"},"]"),n("span",{class:"mopen"},"["),n("span",{class:"mord"},"0"),n("span",{class:"mclose"},"]")])])]),s("，"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"w")]),n("annotation",{encoding:"application/x-tex"},"w")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.4306em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")])])]),s("，然后它不是写出值，想这里的"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("msup",null,[n("mi",null,"w"),n("mn",null,"2")])]),n("annotation",{encoding:"application/x-tex"},"w^{2}")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.8141em"}}),n("span",{class:"mord"},[n("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.8141em"}},[n("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])])])])])]),s("，TensorFlow使用说明倾向于只写运算符，所以这里就是平方运算，而这两者一起指向乘法运算，以此类推，然后在最后的节点，我猜应该是一个将"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"x"),n("mo",{stretchy:"false"},"["),n("mn",null,"2"),n("mo",{stretchy:"false"},"]"),n("mo",{stretchy:"false"},"["),n("mn",null,"0"),n("mo",{stretchy:"false"},"]")]),n("annotation",{encoding:"application/x-tex"},"x[2][0]")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),n("span",{class:"mord mathnormal"},"x"),n("span",{class:"mopen"},"["),n("span",{class:"mord"},"2"),n("span",{class:"mclose"},"]"),n("span",{class:"mopen"},"["),n("span",{class:"mord"},"0"),n("span",{class:"mclose"},"]")])])]),s("加上去得到最终值的加法运算。")])],-1),w=n("p",null,[s("我认为计算图用第一种方式会更容易理解，但是如果你去看TensorFlow的使用说明，如果你看到说明里的"),n("strong",null,"计算图"),s("，你会看到另一种表示方式，节点都用运算来标记而不是值，但这两种呈现方式表达的是同样的计算图。")],-1),b=[l,c,i,u,r,m,d,k,h,v,w];function g(y,x){return e(),p("div",null,b)}const T=t(o,[["render",g],["__file","吴恩达.html.vue"]]),E=JSON.parse('{"path":"/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/04.%20Project/Type/Artificial_Intelligence/%E5%AD%97%E5%85%B8%E5%9E%8B/09.%20Python%E5%BA%93/Tensorflow/%E5%90%B4%E6%81%A9%E8%BE%BE.html","title":"TensorFlow","lang":"zh-CN","frontmatter":{"description":"TensorFlow 目录 吴恩达深度学习视频中的一些杂记 TensorFlow很强大。你只需说明如何计算损失函数，它就能求导。而且用一两行代码就能运用梯度优化器，Adam优化器或者其他优化器。 （注意区别TensorFlow和Transformer，有点像，但一个是python包一个是模型） 举个例子： J(w)=w2−10w+25，这就是损失函数，...","head":[["meta",{"property":"og:url","content":"http://192.168.0.101:8080/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/04.%20Project/Type/Artificial_Intelligence/%E5%AD%97%E5%85%B8%E5%9E%8B/09.%20Python%E5%BA%93/Tensorflow/%E5%90%B4%E6%81%A9%E8%BE%BE.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"TensorFlow"}],["meta",{"property":"og:description","content":"TensorFlow 目录 吴恩达深度学习视频中的一些杂记 TensorFlow很强大。你只需说明如何计算损失函数，它就能求导。而且用一两行代码就能运用梯度优化器，Adam优化器或者其他优化器。 （注意区别TensorFlow和Transformer，有点像，但一个是python包一个是模型） 举个例子： J(w)=w2−10w+25，这就是损失函数，..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"LincZero"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"TensorFlow\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"TensorFlow","slug":"tensorflow","link":"#tensorflow","children":[]},{"level":1,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":1,"title":"吴恩达深度学习视频中的一些杂记","slug":"吴恩达深度学习视频中的一些杂记","link":"#吴恩达深度学习视频中的一些杂记","children":[{"level":2,"title":"最小化损失函数","slug":"最小化损失函数","link":"#最小化损失函数","children":[]},{"level":2,"title":"添加训练数据","slug":"添加训练数据","link":"#添加训练数据","children":[]},{"level":2,"title":"更精简的写法","slug":"更精简的写法","link":"#更精简的写法","children":[]},{"level":2,"title":"一些补充","slug":"一些补充","link":"#一些补充","children":[{"level":3,"title":"补充：运算符号问题","slug":"补充-运算符号问题","link":"#补充-运算符号问题","children":[]},{"level":3,"title":"补充：placeholder的好处","slug":"补充-placeholder的好处","link":"#补充-placeholder的好处","children":[]},{"level":3,"title":"补充：with写法","slug":"补充-with写法","link":"#补充-with写法","children":[]},{"level":3,"title":"补充：换最佳化算法","slug":"补充-换最佳化算法","link":"#补充-换最佳化算法","children":[]}]},{"level":2,"title":"TensorFlow的一些原理（计算图）","slug":"tensorflow的一些原理-计算图","link":"#tensorflow的一些原理-计算图","children":[]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":6.09,"words":1827},"filePathRelative":"MdNote_Public/01. 设计开发与数据生产/Develop/04. Project/Type/Artificial_Intelligence/字典型/09. Python库/Tensorflow/吴恩达.md","autoDesc":true}');export{T as comp,E as data};
