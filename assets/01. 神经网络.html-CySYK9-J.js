import{_ as o,c as t,a as n,b as s,d as l,e as i,o as e,r as m}from"./app-C_O3u0sp.js";const c="/assets/image-20220908165536244-DRlZCScE.png",r="/assets/image-20220908171058818-CAyKxMel.png",u="/assets/image-20220908124803285-WU4aQe_9.png",h="/assets/image-20220908144206121-9H1FhPbi.png",d="/assets/image-20220908144838773-4tztnMkn.png",g="/assets/image-20220908144816755-DxqVHDgT.png",k="/assets/image-20220909142218767-wMVQWFW5.png",y="/assets/image-20220909100331462-YgNpifxm.png",v="/assets/image-20220909100137536-Hto0XOcL.png",b="/assets/image-20220909095403322-B4k0OwgI.png",w={},x={class:"katex"},f={class:"katex-html","aria-hidden":"true"},_={class:"base"},z={class:"mord accent"},M={class:"vlist-t"},L={class:"vlist-r"},A={class:"vlist",style:{height:"0.714em"}},j={style:{top:"-3em"}},B={class:"accent-body",style:{left:"-0.2077em"}},N={class:"overlay",style:{height:"0.714em",width:"0.471em"}},E={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},S={class:"katex"},D={class:"katex-html","aria-hidden":"true"},q={class:"base"},P={class:"mord"},C={class:"mord accent"},T={class:"vlist-t"},H={class:"vlist-r"},Y={class:"vlist",style:{height:"0.714em"}},R={style:{top:"-3em"}},F={class:"accent-body",style:{left:"-0.2355em"}},W={class:"overlay",style:{height:"0.714em",width:"0.471em"}},U={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},I={class:"katex"},O={class:"katex-html","aria-hidden":"true"},J={class:"base"},Z={class:"mord"},V={class:"mord accent"},X={class:"vlist-t"},G={class:"vlist-r"},Q={class:"vlist",style:{height:"0.714em"}},K={style:{top:"-3em"}},$={class:"accent-body",style:{left:"-0.2355em"}},ss={class:"overlay",style:{height:"0.714em",width:"0.471em"}},as={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},ns={class:"katex-block"},ts={class:"katex-display"},es={class:"katex"},ls={class:"katex-html","aria-hidden":"true"},ps={class:"base"},is={class:"mord"},os={class:"mord accent"},ms={class:"vlist-t"},cs={class:"vlist-r"},rs={class:"vlist",style:{height:"0.714em"}},us={style:{top:"-3em"}},hs={class:"accent-body",style:{left:"-0.1522em"}},ds={class:"overlay",style:{height:"0.714em",width:"0.471em"}},gs={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},ks={class:"base"},ys={class:"mord"},vs={class:"mord accent"},bs={class:"vlist-t"},ws={class:"vlist-r"},xs={class:"vlist",style:{height:"0.714em"}},fs={style:{top:"-3em"}},_s={class:"accent-body",style:{left:"-0.2355em"}},zs={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Ms={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Ls={class:"katex"},As={class:"katex-html","aria-hidden":"true"},js={class:"base"},Bs={class:"mord accent"},Ns={class:"vlist-t"},Es={class:"vlist-r"},Ss={class:"vlist",style:{height:"0.714em"}},Ds={style:{top:"-3em"}},qs={class:"accent-body",style:{left:"-0.2077em"}},Ps={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Cs={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Ts={class:"katex"},Hs={class:"katex-html","aria-hidden":"true"},Ys={class:"base"},Rs={class:"mord"},Fs={class:"mord accent"},Ws={class:"vlist-t"},Us={class:"vlist-r"},Is={class:"vlist",style:{height:"0.714em"}},Os={style:{top:"-3em"}},Js={class:"accent-body",style:{left:"-0.2355em"}},Zs={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Vs={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Xs={class:"katex"},Gs={class:"katex-html","aria-hidden":"true"},Qs={class:"base"},Ks={class:"mord"},$s={class:"mord accent"},sa={class:"vlist-t"},aa={class:"vlist-r"},na={class:"vlist",style:{height:"0.714em"}},ta={style:{top:"-3em"}},ea={class:"accent-body",style:{left:"-0.2355em"}},la={class:"overlay",style:{height:"0.714em",width:"0.471em"}},pa={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},ia={href:"https://blog.csdn.net/bitcarmanlee/article/details/78819025",target:"_blank",rel:"noopener noreferrer"},oa={href:"https://zhuanlan.zhihu.com/p/429099813",target:"_blank",rel:"noopener noreferrer"},ma={class:"katex-block"},ca={class:"katex-display"},ra={class:"katex"},ua={class:"katex-html","aria-hidden":"true"},ha={class:"base"},da={class:"mord"},ga={class:"msupsub"},ka={class:"vlist-t vlist-t2"},ya={class:"vlist-r"},va={class:"vlist",style:{height:"0.3448em"}},ba={style:{top:"-2.545em","margin-left":"-0.1076em","margin-right":"0.05em"}},wa={class:"sizing reset-size6 size3 mtight"},xa={class:"mord mtight"},fa={class:"mord accent mtight"},_a={class:"vlist-t"},za={class:"vlist-r"},Ma={class:"vlist",style:{height:"0.714em"}},La={style:{top:"-2.714em"}},Aa={class:"accent-body",style:{left:"-0.1522em"}},ja={class:"overlay mtight",style:{height:"0.714em",width:"0.471em"}},Ba={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Na={class:"mord accent"},Ea={class:"vlist-t"},Sa={class:"vlist-r"},Da={class:"vlist",style:{height:"0.714em"}},qa={style:{top:"-3em"}},Pa={class:"accent-body",style:{left:"-0.2077em"}},Ca={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Ta={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Ha={class:"katex-block"},Ya={class:"katex-display"},Ra={class:"katex"},Fa={class:"katex-html","aria-hidden":"true"},Wa={class:"base"},Ua={class:"mord"},Ia={class:"mord",style:{color:"orange"}},Oa={class:"msupsub"},Ja={class:"vlist-t vlist-t2"},Za={class:"vlist-r"},Va={class:"vlist",style:{height:"0.3448em"}},Xa={style:{top:"-2.545em","margin-left":"-0.1076em","margin-right":"0.05em"}},Ga={class:"sizing reset-size6 size3 mtight",style:{color:"orange"}},Qa={class:"mord mtight",style:{color:"orange"}},Ka={class:"mord accent mtight",style:{color:"orange"}},$a={class:"vlist-t"},sn={class:"vlist-r"},an={class:"vlist",style:{height:"0.714em"}},nn={style:{top:"-2.714em"}},tn={class:"accent-body",style:{left:"-0.1522em"}},en={class:"overlay mtight",style:{color:"orange",height:"0.714em",width:"0.471em"}},ln={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},pn={class:"mord accent",style:{color:"orange"}},on={class:"vlist-t"},mn={class:"vlist-r"},cn={class:"vlist",style:{height:"0.714em"}},rn={style:{top:"-3em"}},un={class:"accent-body",style:{left:"-0.2077em"}},hn={class:"overlay",style:{color:"orange",height:"0.714em",width:"0.471em"}},dn={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},gn={class:"base"},kn={class:"mord accent"},yn={class:"vlist-t"},vn={class:"vlist-r"},bn={class:"vlist",style:{height:"0.714em"}},wn={style:{top:"-3em"}},xn={class:"accent-body",style:{left:"-0.1522em"}},fn={class:"overlay",style:{height:"0.714em",width:"0.471em"}},_n={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},zn={class:"base"},Mn={class:"mord"},Ln={class:"mord",style:{color:"orange"}},An={class:"msupsub"},jn={class:"vlist-t vlist-t2"},Bn={class:"vlist-r"},Nn={class:"vlist",style:{height:"0.3448em"}},En={style:{top:"-2.545em","margin-left":"-0.1076em","margin-right":"0.05em"}},Sn={class:"sizing reset-size6 size3 mtight",style:{color:"orange"}},Dn={class:"mord mtight",style:{color:"orange"}},qn={class:"mord accent mtight",style:{color:"orange"}},Pn={class:"vlist-t"},Cn={class:"vlist-r"},Tn={class:"vlist",style:{height:"0.714em"}},Hn={style:{top:"-2.714em"}},Yn={class:"accent-body",style:{left:"-0.1522em"}},Rn={class:"overlay mtight",style:{color:"orange",height:"0.714em",width:"0.471em"}},Fn={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Wn={class:"mord",style:{color:"orange"}},Un={class:"mord accent",style:{color:"orange"}},In={class:"vlist-t"},On={class:"vlist-r"},Jn={class:"vlist",style:{height:"0.714em"}},Zn={style:{top:"-3em"}},Vn={class:"accent-body",style:{left:"-0.2077em"}},Xn={class:"overlay",style:{color:"orange",height:"0.714em",width:"0.471em"}},Gn={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Qn={class:"katex-block"},Kn={class:"katex-display"},$n={class:"katex"},st={class:"katex-html","aria-hidden":"true"},at={class:"base"},nt={class:"mord accent"},tt={class:"vlist-t"},et={class:"vlist-r"},lt={class:"vlist",style:{height:"0.714em"}},pt={style:{top:"-3em"}},it={class:"accent-body",style:{left:"-0.1522em"}},ot={class:"overlay",style:{height:"0.714em",width:"0.471em"}},mt={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"};function ct(rt,a){const p=m("ExternalLinkIcon");return e(),t("div",null,[a[138]||(a[138]=n('<h1 id="吴恩达机器学习" tabindex="-1"><a class="header-anchor" href="#吴恩达机器学习"><span>吴恩达机器学习</span></a></h1><h1 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h1><p>第二课导读</p><ul><li>神经网络（Neural Networks） <ul><li>推理（预言）</li><li>训练</li></ul></li><li>建立机器学习系统的一些实用建议</li><li>决策树（Decision Tree）</li></ul><h1 id="神经网络-neural-networks" tabindex="-1"><a class="header-anchor" href="#神经网络-neural-networks"><span>神经网络（Neural Networks）</span></a></h1><h2 id="入门" tabindex="-1"><a class="header-anchor" href="#入门"><span>入门</span></a></h2><h3 id="入门-1" tabindex="-1"><a class="header-anchor" href="#入门-1"><span>入门</span></a></h3><h4 id="起源" tabindex="-1"><a class="header-anchor" href="#起源"><span>起源</span></a></h4><p>模拟神经元和大脑（Neuron &amp; Brain）</p><p>研究历史</p><ul><li>起源：1950年尝试去模拟大脑</li><li>1980~1990年，再次流行</li><li>2005年，兴起</li><li>神经网络近期增长，也很大程度因为数据的数量多了很多，即大数据。这得以去训练大型神经网络</li></ul><p>大脑如何运行？</p><ul><li>一个神经元可以影响输出其他神经元，神经元包括树突轴突神经末梢等，……</li><li>简化数学模型：输入神经元影响输出神经元，神经元可以影响多个神经元，神经元也可以被多个神经元影响</li></ul><h4 id="神经网络为何如此高效" tabindex="-1"><a class="header-anchor" href="#神经网络为何如此高效"><span>神经网络为何如此高效</span></a></h4><p>CPU GPU 能并行运算，擅长做非常大的矩阵运算，矩阵运算通常也是可并行计算的</p><p>在编程时应该尽量用矩阵运算去代替for循环，以提高运算效率</p><h3 id="概念" tabindex="-1"><a class="header-anchor" href="#概念"><span>概念</span></a></h3><h4 id="激活函数-activation-function" tabindex="-1"><a class="header-anchor" href="#激活函数-activation-function"><span>激活函数（Activation Function）</span></a></h4><p>定义一个激活函数，一般选择Sigomid作为激活函数</p>',19)),a[139]||(a[139]=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"a"),s("mo",null,"="),s("mi",null,"g"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mi",null,"w"),s("mi",null,"x"),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")")])])])]),s("mspace",{linebreak:"newline"}),s("mtext",null,"其中"),s("mi",null,"a"),s("mtext",null,"是激活 "),s("mi",null,"a"),s("mi",null,"c"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"v"),s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n"),s("mtext",null," 的意思，这个函数也叫激活函数")]),s("annotation",{encoding:"application/x-tex"}," a=g(x)=\\frac1{1+e^{-(wx+b)}}\\\\ 其中a是激活~activation~的意思，这个函数也叫激活函数 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.1088em","vertical-align":"-0.7873em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.296em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.814em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mathnormal mtight"},"b"),s("span",{class:"mclose mtight"},")")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7873em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord cjk_fallback"},"其中"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord cjk_fallback"},"是激活"),s("span",{class:"mspace nobreak"}," "),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace nobreak"}," "),s("span",{class:"mord cjk_fallback"},"的意思，这个函数也叫激活函数")])])])])],-1)),a[140]||(a[140]=s("p",null,"写程序时也经常将这个激活函数分两条语句：",-1)),a[141]||(a[141]=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",{rowspacing:"0.36em",columnalign:"left left",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",null,"z"),s("mo",null,"="),s("mi",null,"w"),s("mi",null,"x"),s("mo",null,"+"),s("mi",null,"b")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",null,"a"),s("mo",null,"="),s("mi",null,"g"),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"z")])])])])])])])])])]),s("annotation",{encoding:"application/x-tex"}," \\begin{cases} z=wx+b\\\\ a=g(z)=\\frac1{1+e^{-z}} \\end{cases} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3em","vertical-align":"-1.25em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.69em"}},[s("span",{style:{top:"-3.69em"}},[s("span",{class:"pstrut",style:{height:"3.008em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal"},"b")])]),s("span",{style:{top:"-2.25em"}},[s("span",{class:"pstrut",style:{height:"3.008em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7027em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4033em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.19em"}},[s("span")])])])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1)),a[142]||(a[142]=n(`<p>即</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">,</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> b
f_x <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>mp<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="神经元-neuron-单元-units" tabindex="-1"><a class="header-anchor" href="#神经元-neuron-单元-units"><span>神经元（Neuron）/ 单元（Units）</span></a></h4><p>对于一个 Neuron (神经元) 来说，对他输入x便会根据激活函数输出a</p><p>这里的神经元在机器神经网络中也被简称为单元（Units）</p><h4 id="层-layer" tabindex="-1"><a class="header-anchor" href="#层-layer"><span>层（Layer）</span></a></h4><ul><li><p>层</p><ul><li><p>层（Layer），说详细点也可以叫 神经网络层（Neural Network Layer）</p></li><li><p>一个神经网络有一或多个层，每一层可以有一或多个 Neuron</p></li><li><p>同一层的 Neuron 有相同的特性</p><p>例如：同一层中的每一个 Neuron 他们的激活函数模型一样 (比如都是Sigmoid)，但是函数中的参数可能不一样（例如w和b不同）</p></li></ul></li><li><p>层包括</p><ul><li>这些层包含输入层（Input Layout）、 输出层（Output Layouts）、中间层 / 隐藏层（Middle Layer / Hidden Layer） <ul><li>输入层补充：不包含 Neuron，就是原始数据</li><li>输出层补充：一般只有一个 Neuron，得到最终结果</li><li>中间层补充：也叫做隐藏层的原因是，在训练集中，只能看到输入和输出结果，中间的过程不能看 (也看不懂)</li></ul></li><li>层的计数是从0开始的。例如输入层和输出层直接有三个中间层，他们分别是 “Layer0~Layer4”</li></ul></li><li><p>向量化</p><ul><li>不同层之间的 Neuron，上一层的每个 Neuron 输出给下一层的所有 Neuron，下一层的每个 Neuron 接收上一层所有Neuron，即 “全射”</li><li>一般将一个层中的所有 Neuron 包成一个向量，通过矩阵叉乘的方式就可以将上一个层全射到下一个层中</li></ul></li></ul><h4 id="神经网络-neural-networks-1" tabindex="-1"><a class="header-anchor" href="#神经网络-neural-networks-1"><span>神经网络（Neural Networks）</span></a></h4><blockquote><h5 id="单中间层的结构" tabindex="-1"><a class="header-anchor" href="#单中间层的结构"><span>单中间层的结构</span></a></h5></blockquote><p>每一个 Neuron 都有一个Sigmoid的激活函数</p><p><mark>符号表示</mark></p>`,11)),s("ul",null,[a[19]||(a[19]=n('<li>右上角加<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mtext> </mtext><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[~]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mspace nobreak"> </span><span class="mclose">]</span></span></span></span>的上标表示处于第几个网络层</li><li>右上角加<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>的上标表示用的是第几个样本（当然，在向量化的公式里你看不到这个表示的，而且一般也是用下标表示的）</li><li>右下角数字<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>的下标表示是该网络层的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>个单元。是输入层的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>个特制，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>≠</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x^{(1)}\\not=x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0824em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>w</mi><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mtext>、</mtext><msubsup><mi>b</mi><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">w_j^{[l]}、b_j^{[l]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4578em;vertical-align:-0.413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span></span></span></span>表示处于第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>个神经网络层的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>个神经元所使用Sigmoid函数的参数</li>',4)),s("li",null,[s("span",x,[a[4]||(a[4]=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec x")])])],-1)),s("span",f,[s("span",_,[a[3]||(a[3]=s("span",{class:"strut",style:{height:"0.714em"}},null,-1)),s("span",z,[s("span",M,[s("span",L,[s("span",A,[a[2]||(a[2]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1)),s("span",j,[a[1]||(a[1]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",B,[s("span",N,[(e(),t("svg",E,a[0]||(a[0]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])])])])]),a[11]||(a[11]=l("表示输入层的矢量表示，等价于")),s("span",S,[a[10]||(a[10]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\\vec a^{[l]}</annotation></semantics></math></span>',1)),s("span",D,[s("span",q,[a[9]||(a[9]=s("span",{class:"strut",style:{height:"0.888em"}},null,-1)),s("span",P,[s("span",C,[s("span",T,[s("span",H,[s("span",Y,[a[7]||(a[7]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"a")],-1)),s("span",R,[a[6]||(a[6]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",F,[s("span",W,[(e(),t("svg",U,a[5]||(a[5]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[8]||(a[8]=n('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span>',1))])])])])]),s("li",null,[s("span",I,[a[17]||(a[17]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\\vec a^{[l]}</annotation></semantics></math></span>',1)),s("span",O,[s("span",J,[a[16]||(a[16]=s("span",{class:"strut",style:{height:"0.888em"}},null,-1)),s("span",Z,[s("span",V,[s("span",X,[s("span",G,[s("span",Q,[a[14]||(a[14]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"a")],-1)),s("span",K,[a[13]||(a[13]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",$,[s("span",ss,[(e(),t("svg",as,a[12]||(a[12]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[15]||(a[15]=n('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span>',1))])])])]),a[18]||(a[18]=n('表示序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> (注意从0开始计数) 的神经网络层的输出的矢量表示',3))])]),a[143]||(a[143]=s("p",null,[s("img",{src:c,alt:"image-20220908165536244",loading:"lazy"})],-1)),a[144]||(a[144]=s("blockquote",null,[s("h5",{id:"多中间层的结构",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#多中间层的结构"},[s("span",null,"多中间层的结构")])])],-1)),s("p",ns,[s("span",ts,[s("span",es,[a[40]||(a[40]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>a</mi><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msubsup><mover accent="true"><mi>w</mi><mo>⃗</mo></mover><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mo>⋅</mo><msup><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>+</mo><msubsup><mi>b</mi><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> a_j^{[l]}=g(\\vec w_j^{[l]}\\cdot \\vec a^{[l-1]}+b_j^{[l]}) </annotation></semantics></math></span>',1)),s("span",ls,[a[38]||(a[38]=n('<span class="base"><span class="strut" style="height:1.4578em;vertical-align:-0.413em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span>',1)),s("span",ps,[a[24]||(a[24]=s("span",{class:"strut",style:{height:"1.4578em","vertical-align":"-0.413em"}},null,-1)),a[25]||(a[25]=s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g",-1)),a[26]||(a[26]=s("span",{class:"mopen"},"(",-1)),s("span",is,[s("span",os,[s("span",ms,[s("span",cs,[s("span",rs,[a[22]||(a[22]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1)),s("span",us,[a[21]||(a[21]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",hs,[s("span",ds,[(e(),t("svg",gs,a[20]||(a[20]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[23]||(a[23]=n('<span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span>',1))]),a[27]||(a[27]=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1)),a[28]||(a[28]=s("span",{class:"mbin"},"⋅",-1)),a[29]||(a[29]=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1))]),s("span",ks,[a[34]||(a[34]=s("span",{class:"strut",style:{height:"1.0213em","vertical-align":"-0.0833em"}},null,-1)),s("span",ys,[s("span",vs,[s("span",bs,[s("span",ws,[s("span",xs,[a[32]||(a[32]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"a")],-1)),s("span",fs,[a[31]||(a[31]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",_s,[s("span",zs,[(e(),t("svg",Ms,a[30]||(a[30]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[33]||(a[33]=n('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span>',1))]),a[35]||(a[35]=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1)),a[36]||(a[36]=s("span",{class:"mbin"},"+",-1)),a[37]||(a[37]=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1))]),a[39]||(a[39]=n('<span class="base"><span class="strut" style="height:1.4578em;vertical-align:-0.413em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span>',1))])])])]),a[145]||(a[145]=s("p",null,[s("mark",null,"符号表示")],-1)),s("ul",null,[a[60]||(a[60]=n('<li>右上角加<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mtext> </mtext><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[~]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mspace nobreak"> </span><span class="mclose">]</span></span></span></span>的上标表示处于第几个网络层</li><li>右上角加<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mclose">)</span></span></span></span>的上标表示用的是第几个样本（当然，在向量化的公式里你看不到这个表示的，而且一般也是用下标表示的）</li><li>右下角数字<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>的下标表示是该网络层的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>个单元。是输入层的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>个特制，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>≠</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x^{(1)}\\not=x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0824em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>w</mi><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mtext>、</mtext><msubsup><mi>b</mi><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">w_j^{[l]}、b_j^{[l]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4578em;vertical-align:-0.413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span></span></span></span></span></span></span></span></span></span>表示处于第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>个神经网络层的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>个神经元所使用Sigmoid函数的参数</li>',4)),s("li",null,[s("span",Ls,[a[45]||(a[45]=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec x")])])],-1)),s("span",As,[s("span",js,[a[44]||(a[44]=s("span",{class:"strut",style:{height:"0.714em"}},null,-1)),s("span",Bs,[s("span",Ns,[s("span",Es,[s("span",Ss,[a[43]||(a[43]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1)),s("span",Ds,[a[42]||(a[42]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",qs,[s("span",Ps,[(e(),t("svg",Cs,a[41]||(a[41]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])])])])]),a[52]||(a[52]=l("表示输入层的矢量表示，等价于")),s("span",Ts,[a[51]||(a[51]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\\vec a^{[l]}</annotation></semantics></math></span>',1)),s("span",Hs,[s("span",Ys,[a[50]||(a[50]=s("span",{class:"strut",style:{height:"0.888em"}},null,-1)),s("span",Rs,[s("span",Fs,[s("span",Ws,[s("span",Us,[s("span",Is,[a[48]||(a[48]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"a")],-1)),s("span",Os,[a[47]||(a[47]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",Js,[s("span",Zs,[(e(),t("svg",Vs,a[46]||(a[46]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[49]||(a[49]=n('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span>',1))])])])])]),s("li",null,[s("span",Xs,[a[58]||(a[58]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\\vec a^{[l]}</annotation></semantics></math></span>',1)),s("span",Gs,[s("span",Qs,[a[57]||(a[57]=s("span",{class:"strut",style:{height:"0.888em"}},null,-1)),s("span",Ks,[s("span",$s,[s("span",sa,[s("span",aa,[s("span",na,[a[55]||(a[55]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"a")],-1)),s("span",ta,[a[54]||(a[54]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",ea,[s("span",la,[(e(),t("svg",pa,a[53]||(a[53]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[56]||(a[56]=n('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">]</span></span></span></span></span></span></span></span>',1))])])])]),a[59]||(a[59]=n('表示序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span> (注意从0开始计数) 的神经网络层的输出的矢量表示',3))])]),a[146]||(a[146]=n('<p><img src="'+r+'" alt="image-20220908171058818" loading="lazy"></p><h3 id="使用举例" tabindex="-1"><a class="header-anchor" href="#使用举例"><span>使用举例</span></a></h3><h4 id="举例-需求预测-demand-prediction" tabindex="-1"><a class="header-anchor" href="#举例-需求预测-demand-prediction"><span>举例 - 需求预测（Demand Prediction）</span></a></h4><p>例如我们要根据价格、运费、促销、材质来预测是否畅销</p><p>大概原理如下图，但是不需要手动去设置特征，中间层是自动算的</p><p><img src="'+u+'" alt="image-20220908124803285" loading="lazy"></p><h4 id="举例-图像感知、物品识别" tabindex="-1"><a class="header-anchor" href="#举例-图像感知、物品识别"><span>举例 - 图像感知、物品识别</span></a></h4><p>图像的输入方式</p><p><img src="'+h+'" alt="image-20220908144206121" loading="lazy"></p><p>不同层的分工</p><blockquote><h5 id="人脸识别" tabindex="-1"><a class="header-anchor" href="#人脸识别"><span>人脸识别</span></a></h5></blockquote><p><img src="'+d+'" alt="image-20220908144838773" loading="lazy"></p><blockquote><h5 id="车辆检测" tabindex="-1"><a class="header-anchor" href="#车辆检测"><span>车辆检测</span></a></h5></blockquote><p><img src="'+g+'" alt="image-20220908144816755" loading="lazy"></p><h2 id="前向传播-forward-propagation" tabindex="-1"><a class="header-anchor" href="#前向传播-forward-propagation"><span>前向传播（Forward Propagation）</span></a></h2><p>另参考：</p>',16)),s("ul",null,[s("li",null,[s("a",ia,[a[61]||(a[61]=l("【CSDN】前向传播算法(Forward propagation)与反向传播算法(Back propagation)")),i(p)])]),s("li",null,[s("a",oa,[a[62]||(a[62]=l("【知乎】什么是前向传播算法(Forward propagation)？")),i(p)])])]),a[147]||(a[147]=n('<h3 id="概念-1" tabindex="-1"><a class="header-anchor" href="#概念-1"><span>概念</span></a></h3><ul><li><p><strong>前向传播</strong> / 正向传播（Forward Propagation）算法</p><ul><li><p>简单解释：将上一层的输出作为下一层的输入，并计算下一层的输出，一直到运算到输出层为止</p><p>当你训练完神经网络后，你就可以通过前向传播来用训练后的模型进行预测</p></li><li><p>其他特性：随着靠近输出层，隐藏层的 Neuron (Units) 数量会减少</p></li></ul></li><li><p><strong>反向传播</strong>（Backward Propagation / Back Propagation）算法</p><ul><li>与前向传播相对应</li></ul></li></ul><h3 id="公式" tabindex="-1"><a class="header-anchor" href="#公式"><span>公式</span></a></h3><p>对于前向传播来说，不管维度多高，其过程都可以用如下公式表示：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msup><mi>a</mi><mn>1</mn></msup><mo>∗</mo><msup><mi>W</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> a^2=\\sigma(z^2)=\\sigma(a^1*W^2+b^2) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8641em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中，上标代表层数，星号表示卷积，b表示偏置项bias，σ表示激活函数</p><p>例如：单个网络层的前向传播：</p><p><img src="'+k+`" alt="image-20220909142218767" loading="lazy"></p><h3 id="代码基础" tabindex="-1"><a class="header-anchor" href="#代码基础"><span>代码基础</span></a></h3><h4 id="numpy中数据的形式" tabindex="-1"><a class="header-anchor" href="#numpy中数据的形式"><span>NumPy中数据的形式</span></a></h4><p>NumPy 存储数据的方式：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>		<span class="token comment"># 这是一个矩阵</span>
    <span class="token punctuation">[</span><span class="token number">200.0</span><span class="token punctuation">,</span> <span class="token number">17.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">425.0</span><span class="token punctuation">,</span> <span class="token number">18.5</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

x  <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>		<span class="token comment"># 这是一个4x2矩阵，即四行两列矩阵</span>
    <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="tensorflow中数据形式" tabindex="-1"><a class="header-anchor" href="#tensorflow中数据形式"><span>Tensorflow中数据形式</span></a></h4><p>这里举一个例子：通过温度和时间来判断咖啡是否煮熟（不会未熟或过熟）</p><table><thead><tr><th>温度</th><th>分钟</th><th>是否好咖啡</th></tr></thead><tbody><tr><td>200</td><td>17.0</td><td>1</td></tr><tr><td>425</td><td>18.5</td><td>0</td></tr><tr><td>...</td><td>...</td><td>...</td></tr></tbody></table><p>神经网络前向传播的代码：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">200.0</span><span class="token punctuation">,</span> <span class="token number">17.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>					<span class="token comment"># 输入数据x</span>
layer_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>	<span class="token comment"># 第一层神经网络层，定义该层有三个单元，使用Sigmoid作为激活函数</span>
a1 <span class="token operator">=</span> layer_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>									<span class="token comment"># 将输入数据x传给layer1得到输出</span>

layer_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>	<span class="token comment"># （重复，不过单元的数量减少为1）</span>
a2 <span class="token operator">=</span> layer_1<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>关于数据形式的补充：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># x：</span>
<span class="token comment"># 这里的输入向量x变量，需要是一个NumPy的行矩阵的形式</span>

<span class="token comment"># a1：</span>
tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.2</span> <span class="token number">0.7</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>
<span class="token comment"># a1.numpy()：</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.4661001</span><span class="token punctuation">,</span> <span class="token number">1.12516</span><span class="token punctuation">,</span> <span class="token number">3.2159438</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>

<span class="token comment"># a2：</span>
tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>
<span class="token comment"># a2.numpy()：</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="代码实现" tabindex="-1"><a class="header-anchor" href="#代码实现"><span>代码实现</span></a></h3><h4 id="举例-手写体数字识别" tabindex="-1"><a class="header-anchor" href="#举例-手写体数字识别"><span>举例 - 手写体数字识别</span></a></h4><p>前向传播中Units的减少</p><p><img src="`+y+'" alt="image-20220909100331462" loading="lazy"></p><p>代码</p><p><img src="'+v+'" alt="image-20220909100137536" loading="lazy"></p><h4 id="举例-判断咖啡是否煮得好" tabindex="-1"><a class="header-anchor" href="#举例-判断咖啡是否煮得好"><span>举例 - 判断咖啡是否煮得好</span></a></h4><p>这里举一个例子：通过温度和时间来判断咖啡是否煮熟（不会未熟或过熟）</p><p><img src="'+b+`" alt="image-20220909095403322" loading="lazy"></p><p>代码：（课程中用的TensorFlow工具）</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">200.0</span><span class="token punctuation">,</span> <span class="token number">17.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>					<span class="token comment"># 输入数据x</span>
layer_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>	<span class="token comment"># 第一层神经网络层，定义该层有三个单元，使用Sigmoid作为激活函数</span>
a1 <span class="token operator">=</span> layer_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>									<span class="token comment"># 将输入数据x传给layer1得到输出</span>

layer_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>	<span class="token comment"># （重复，不过单元的数量减少为1）</span>
a2 <span class="token operator">=</span> layer_1<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="代码原理" tabindex="-1"><a class="header-anchor" href="#代码原理"><span>代码原理</span></a></h3><p>用TensorFlow实现</p><h4 id="未矩阵化" tabindex="-1"><a class="header-anchor" href="#未矩阵化"><span>未矩阵化</span></a></h4><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>W <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a_in <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">dense</span><span class="token punctuation">(</span>a_in<span class="token punctuation">,</span> W<span class="token punctuation">,</span> B<span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    units <span class="token operator">=</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>				<span class="token comment"># shape是[2行,3列]，即 units = 3</span>
    a_out <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>units<span class="token punctuation">)</span>			<span class="token comment"># a_out = [0,0,0]</span>
    
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>units<span class="token punctuation">)</span><span class="token punctuation">:</span>			<span class="token comment"># 遍历该层的三个神经元，j: 0, 1, 2</span>
        w <span class="token operator">=</span> W<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>j<span class="token punctuation">]</span>					<span class="token comment"># 获取该神经元的w和b</span>
        b <span class="token operator">=</span> B<span class="token punctuation">[</span>j<span class="token punctuation">]</span>					<span class="token comment"># ^</span>
        z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">,</span>a_in<span class="token punctuation">)</span> <span class="token operator">+</span> b		<span class="token comment"># 通过sigmoid函数计算输出</span>
        a_out<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> g<span class="token punctuation">(</span>z<span class="token punctuation">)</span>				<span class="token comment"># ^</span>
    <span class="token keyword">return</span> a_out

<span class="token keyword">def</span> <span class="token function">sequential</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    a1 <span class="token operator">=</span> dense<span class="token punctuation">(</span> x<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">)</span>
    a2 <span class="token operator">=</span> dense<span class="token punctuation">(</span>a2<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">)</span>
    a3 <span class="token operator">=</span> dense<span class="token punctuation">(</span>a3<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">)</span>
    a4 <span class="token operator">=</span> dense<span class="token punctuation">(</span>a4<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">)</span>
    f_x <span class="token operator">=</span> a4
    <span class="token keyword">return</span> f_x

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="矩阵化" tabindex="-1"><a class="header-anchor" href="#矩阵化"><span>矩阵化</span></a></h4><p>用矩阵运算改良旧代码，矩阵化后最大的优点是可以充分利用 CPU GPU 并行计算的资源，高效快速</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">dense</span><span class="token punctuation">(</span>A_in<span class="token punctuation">,</span> W<span class="token punctuation">,</span> B<span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    Z <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>A_in<span class="token punctuation">,</span>W<span class="token punctuation">)</span> <span class="token operator">+</span> B
    A_out <span class="token operator">=</span> g<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
    <span class="token keyword">return</span> A_out
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="训练-model-training" tabindex="-1"><a class="header-anchor" href="#训练-model-training"><span>训练（Model Training）</span></a></h2><h3 id="代码实现-1" tabindex="-1"><a class="header-anchor" href="#代码实现-1"><span>代码实现</span></a></h3><blockquote><h5 id="代码实现1" tabindex="-1"><a class="header-anchor" href="#代码实现1"><span>代码实现1</span></a></h5></blockquote><p>还是之前那个判断咖啡是否煮得好的例子</p><p>之前是手动一层一层去传播的，现在可以不用</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>layer_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>	<span class="token comment"># 定义层</span>
layer_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>layout_1<span class="token punctuation">,</span> laoyout_2<span class="token punctuation">]</span><span class="token punctuation">)</span>		<span class="token comment"># 定义一个神经网络</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>									<span class="token comment"># 定义输入矩阵</span>
    <span class="token punctuation">[</span><span class="token number">200.0</span><span class="token punctuation">,</span> <span class="token number">17.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">120.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">425.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">212.0</span><span class="token punctuation">,</span> <span class="token number">18.0</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>							<span class="token comment"># 定义输出向量（可以看成是列矩阵）</span>

<span class="token comment"># model.compile(...) # （这个以后再学）</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>									<span class="token comment"># 训练模型</span>
model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_new<span class="token punctuation">)</span> 							<span class="token comment"># 用模型预测新数据</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><h5 id="代码实现2" tabindex="-1"><a class="header-anchor" href="#代码实现2"><span>代码实现2</span></a></h5></blockquote><div class="language-Python line-numbers-mode" data-ext="Python" data-title="Python"><pre class="language-Python"><code>import tensorflow as tf							# tensorflow包
from tensorflow.keras.layers import Dense		# 可以用来创建层
from tensorflow.keras import Sequential			# 可以用多个层来创建神经网络

model = Sequential([
    Dense(units=25, activation=&#39;sigmoid&#39;),
    Dense(units=15, activation=&#39;sigmoid&#39;),
    Dense(units= 1, activation=&#39;sigmoid&#39;)
])

from tensorflow.keras.losses import BinaryCrossentropy	# 二进制交叉熵
model.comile(loss=BinaryCrossentropy())			# 定义Loss函数
model.fit(X,Y,epoches=100)						# 训练神经网络，Epoches参数为梯度下降的次数
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="训练的三个步骤" tabindex="-1"><a class="header-anchor" href="#训练的三个步骤"><span>训练的三个步骤</span></a></h3><p>训练步骤（Model Training Steps）有三个：</p><h4 id="_1-定义模型、定义层与激活函数" tabindex="-1"><a class="header-anchor" href="#_1-定义模型、定义层与激活函数"><span>① 定义模型、定义层与激活函数</span></a></h4><h4 id="_2-定义loss函数、cost函数" tabindex="-1"><a class="header-anchor" href="#_2-定义loss函数、cost函数"><span>② 定义Loss函数、Cost函数</span></a></h4><h4 id="_3-最优化、模型训练" tabindex="-1"><a class="header-anchor" href="#_3-最优化、模型训练"><span>③ 最优化、模型训练</span></a></h4><h3 id="训练的三个步骤-具体" tabindex="-1"><a class="header-anchor" href="#训练的三个步骤-具体"><span>训练的三个步骤 - 具体</span></a></h3><h4 id="公式中" tabindex="-1"><a class="header-anchor" href="#公式中"><span>公式中</span></a></h4><blockquote><h5 id="_1-定义模型" tabindex="-1"><a class="header-anchor" href="#_1-定义模型"><span>① 定义模型</span></a></h5></blockquote><p>公式</p>`,54)),s("p",ma,[s("span",ca,[s("span",ra,[a[81]||(a[81]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>f</mi><mrow><mover accent="true"><mi>w</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mi>b</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">?</mo></mrow><annotation encoding="application/x-tex"> f_{\\vec w,b}(\\vec x)=? </annotation></semantics></math></span>',1)),s("span",ua,[s("span",ha,[a[75]||(a[75]=s("span",{class:"strut",style:{height:"1.0411em","vertical-align":"-0.2911em"}},null,-1)),s("span",da,[a[71]||(a[71]=s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f",-1)),s("span",ga,[s("span",ka,[s("span",ya,[s("span",va,[s("span",ba,[a[68]||(a[68]=s("span",{class:"pstrut",style:{height:"2.7em"}},null,-1)),s("span",wa,[s("span",xa,[s("span",fa,[s("span",_a,[s("span",za,[s("span",Ma,[a[65]||(a[65]=s("span",{style:{top:"-2.714em"}},[s("span",{class:"pstrut",style:{height:"2.714em"}}),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w")],-1)),s("span",La,[a[64]||(a[64]=s("span",{class:"pstrut",style:{height:"2.714em"}},null,-1)),s("span",Aa,[s("span",ja,[(e(),t("svg",Ba,a[63]||(a[63]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[66]||(a[66]=s("span",{class:"mpunct mtight"},",",-1)),a[67]||(a[67]=s("span",{class:"mord mathnormal mtight"},"b",-1))])])])]),a[69]||(a[69]=s("span",{class:"vlist-s"},"​",-1))]),a[70]||(a[70]=s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2911em"}},[s("span")])],-1))])])]),a[76]||(a[76]=s("span",{class:"mopen"},"(",-1)),s("span",Na,[s("span",Ea,[s("span",Sa,[s("span",Da,[a[74]||(a[74]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1)),s("span",qa,[a[73]||(a[73]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",Pa,[s("span",Ca,[(e(),t("svg",Ta,a[72]||(a[72]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[77]||(a[77]=s("span",{class:"mclose"},")",-1)),a[78]||(a[78]=s("span",{class:"mspace",style:{"margin-right":"0.2778em"}},null,-1)),a[79]||(a[79]=s("span",{class:"mrel"},"=",-1))]),a[80]||(a[80]=s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mclose"},"?")],-1))])])])]),a[148]||(a[148]=s("blockquote",null,[s("h5",{id:"_2-定义loss函数和cost函数",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_2-定义loss函数和cost函数"},[s("span",null,"② 定义Loss函数和Cost函数")])])],-1)),a[149]||(a[149]=s("p",null,"公式",-1)),s("p",Ha,[s("span",Ya,[s("span",Ra,[a[128]||(a[128]=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mstyle",{mathcolor:"orange"},[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"f"),s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mo",{separator:"true"},","),s("mi",null,"b")])]),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")]),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")")]),s("mo",null,"="),s("mo",{stretchy:"false"},"?"),s("mspace",{linebreak:"newline"}),s("mi",null,"J"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mo",{separator:"true"},","),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"m")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"m")]),s("mstyle",{mathcolor:"orange"},[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"f"),s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mo",{separator:"true"},","),s("mi",null,"b")])]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")]),s("mi",null,"i")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"y"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")])]),s("annotation",{encoding:"application/x-tex"}," {\\color{orange}L(f_{\\vec w,b}(\\vec x),y)}=?\\\\ J(\\vec w,b)=\\frac1m \\sum^m_{i=1} {\\color{orange}L(f_{\\vec w,b}(\\vec x_i,y_i))} ")])])],-1)),s("span",Fa,[s("span",Wa,[a[98]||(a[98]=s("span",{class:"strut",style:{height:"1.0411em","vertical-align":"-0.2911em"}},null,-1)),s("span",Ua,[a[94]||(a[94]=s("span",{class:"mord mathnormal",style:{color:"orange"}},"L",-1)),a[95]||(a[95]=s("span",{class:"mopen",style:{color:"orange"}},"(",-1)),s("span",Ia,[a[90]||(a[90]=s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em",color:"orange"}},"f",-1)),s("span",Oa,[s("span",Ja,[s("span",Za,[s("span",Va,[s("span",Xa,[a[87]||(a[87]=s("span",{class:"pstrut",style:{height:"2.7em"}},null,-1)),s("span",Ga,[s("span",Qa,[s("span",Ka,[s("span",$a,[s("span",sn,[s("span",an,[a[84]||(a[84]=s("span",{style:{top:"-2.714em"}},[s("span",{class:"pstrut",style:{height:"2.714em"}}),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em",color:"orange"}},"w")],-1)),s("span",nn,[a[83]||(a[83]=s("span",{class:"pstrut",style:{height:"2.714em"}},null,-1)),s("span",tn,[s("span",en,[(e(),t("svg",ln,a[82]||(a[82]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[85]||(a[85]=s("span",{class:"mpunct mtight",style:{color:"orange"}},",",-1)),a[86]||(a[86]=s("span",{class:"mord mathnormal mtight",style:{color:"orange"}},"b",-1))])])])]),a[88]||(a[88]=s("span",{class:"vlist-s"},"​",-1))]),a[89]||(a[89]=s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2911em"}},[s("span")])],-1))])])]),a[96]||(a[96]=s("span",{class:"mopen",style:{color:"orange"}},"(",-1)),s("span",pn,[s("span",on,[s("span",mn,[s("span",cn,[a[93]||(a[93]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{color:"orange"}},"x")],-1)),s("span",rn,[a[92]||(a[92]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",un,[s("span",hn,[(e(),t("svg",dn,a[91]||(a[91]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[97]||(a[97]=n('<span class="mclose" style="color:orange;">)</span><span class="mpunct" style="color:orange;">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;color:orange;">y</span><span class="mclose" style="color:orange;">)</span>',5))]),a[99]||(a[99]=s("span",{class:"mspace",style:{"margin-right":"0.2778em"}},null,-1)),a[100]||(a[100]=s("span",{class:"mrel"},"=",-1))]),a[126]||(a[126]=s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mclose"},"?")],-1)),a[127]||(a[127]=s("span",{class:"mspace newline"},null,-1)),s("span",gn,[a[104]||(a[104]=s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}},null,-1)),a[105]||(a[105]=s("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J",-1)),a[106]||(a[106]=s("span",{class:"mopen"},"(",-1)),s("span",kn,[s("span",yn,[s("span",vn,[s("span",bn,[a[103]||(a[103]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1)),s("span",wn,[a[102]||(a[102]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",xn,[s("span",fn,[(e(),t("svg",_n,a[101]||(a[101]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[107]||(a[107]=n('<span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span>',7))]),s("span",zn,[a[125]||(a[125]=n('<span class="strut" style="height:2.9291em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">m</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span>',5)),s("span",Mn,[a[121]||(a[121]=s("span",{class:"mord mathnormal",style:{color:"orange"}},"L",-1)),a[122]||(a[122]=s("span",{class:"mopen",style:{color:"orange"}},"(",-1)),s("span",Ln,[a[116]||(a[116]=s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em",color:"orange"}},"f",-1)),s("span",An,[s("span",jn,[s("span",Bn,[s("span",Nn,[s("span",En,[a[113]||(a[113]=s("span",{class:"pstrut",style:{height:"2.7em"}},null,-1)),s("span",Sn,[s("span",Dn,[s("span",qn,[s("span",Pn,[s("span",Cn,[s("span",Tn,[a[110]||(a[110]=s("span",{style:{top:"-2.714em"}},[s("span",{class:"pstrut",style:{height:"2.714em"}}),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em",color:"orange"}},"w")],-1)),s("span",Hn,[a[109]||(a[109]=s("span",{class:"pstrut",style:{height:"2.714em"}},null,-1)),s("span",Yn,[s("span",Rn,[(e(),t("svg",Fn,a[108]||(a[108]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[111]||(a[111]=s("span",{class:"mpunct mtight",style:{color:"orange"}},",",-1)),a[112]||(a[112]=s("span",{class:"mord mathnormal mtight",style:{color:"orange"}},"b",-1))])])])]),a[114]||(a[114]=s("span",{class:"vlist-s"},"​",-1))]),a[115]||(a[115]=s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2911em"}},[s("span")])],-1))])])]),a[123]||(a[123]=s("span",{class:"mopen",style:{color:"orange"}},"(",-1)),s("span",Wn,[s("span",Un,[s("span",In,[s("span",On,[s("span",Jn,[a[119]||(a[119]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{color:"orange"}},"x")],-1)),s("span",Zn,[a[118]||(a[118]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",Vn,[s("span",Xn,[(e(),t("svg",Gn,a[117]||(a[117]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[120]||(a[120]=n('<span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight" style="color:orange;"><span class="mord mathnormal mtight" style="color:orange;">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span>',1))]),a[124]||(a[124]=n('<span class="mpunct" style="color:orange;">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord" style="color:orange;"><span class="mord mathnormal" style="margin-right:0.03588em;color:orange;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight" style="color:orange;"><span class="mord mathnormal mtight" style="color:orange;">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose" style="color:orange;">))</span>',4))])])])])])]),a[150]||(a[150]=s("blockquote",null,[s("h5",{id:"_3-最优化",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_3-最优化"},[s("span",null,"③ 最优化")])])],-1)),a[151]||(a[151]=s("p",null,"公式",-1)),s("p",Qn,[s("span",Kn,[s("span",$n,[a[137]||(a[137]=n('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>minimize </mtext><mi>J</mi><mo stretchy="false">(</mo><mover accent="true"><mi>w</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> \\text{minimize }J(\\vec w,b) </annotation></semantics></math></span>',1)),s("span",st,[s("span",at,[a[132]||(a[132]=n('<span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">minimize </span></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mopen">(</span>',4)),s("span",nt,[s("span",tt,[s("span",et,[s("span",lt,[a[131]||(a[131]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1)),s("span",pt,[a[130]||(a[130]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",it,[s("span",ot,[(e(),t("svg",mt,a[129]||(a[129]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),a[133]||(a[133]=s("span",{class:"mpunct"},",",-1)),a[134]||(a[134]=s("span",{class:"mspace",style:{"margin-right":"0.1667em"}},null,-1)),a[135]||(a[135]=s("span",{class:"mord mathnormal"},"b",-1)),a[136]||(a[136]=s("span",{class:"mclose"},")",-1))])])])])]),a[152]||(a[152]=n(`<hr><h4 id="逻辑回归中" tabindex="-1"><a class="header-anchor" href="#逻辑回归中"><span>逻辑回归中</span></a></h4><blockquote><h5 id="_1-定义模型-1" tabindex="-1"><a class="header-anchor" href="#_1-定义模型-1"><span>① 定义模型</span></a></h5></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">,</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> b
f_x <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>mp<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><h5 id="_2-定义loss函数和cost函数-1" tabindex="-1"><a class="header-anchor" href="#_2-定义loss函数和cost函数-1"><span>② 定义Loss函数和Cost函数</span></a></h5></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>loss <span class="token operator">=</span> <span class="token operator">-</span>y <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>f_x<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>f_x<span class="token punctuation">)</span>\\\\
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><blockquote><h5 id="_3-最优化-1" tabindex="-1"><a class="header-anchor" href="#_3-最优化-1"><span>③ 最优化</span></a></h5></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
w <span class="token operator">=</span> w <span class="token operator">-</span> alpha <span class="token operator">*</span> dj_dw
b <span class="token operator">=</span> b <span class="token operator">-</span> alpha <span class="token operator">*</span> dj_dw
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h4 id="神经网络中" tabindex="-1"><a class="header-anchor" href="#神经网络中"><span>神经网络中</span></a></h4><blockquote><h5 id="_1-定义模型-2" tabindex="-1"><a class="header-anchor" href="#_1-定义模型-2"><span>① 定义模型</span></a></h5></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Dense<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><h5 id="_2-定义loss函数和cost函数-2" tabindex="-1"><a class="header-anchor" href="#_2-定义loss函数和cost函数-2"><span>② 定义Loss函数和Cost函数</span></a></h5></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span>BinaryCrossentropy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><blockquote><h5 id="_3-最优化-2" tabindex="-1"><a class="header-anchor" href="#_3-最优化-2"><span>③ 最优化</span></a></h5></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><hr><h2 id="神经网络的优化方法" tabindex="-1"><a class="header-anchor" href="#神经网络的优化方法"><span>神经网络的优化方法</span></a></h2><h3 id="model优化-正则化" tabindex="-1"><a class="header-anchor" href="#model优化-正则化"><span>Model优化 - 正则化</span></a></h3><p>正则化之前介绍过，不再赘述</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span>    kernel_regularizer<span class="token operator">=</span>L2<span class="token punctuation">(</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span>    kernel_regularizer<span class="token operator">=</span>L2<span class="token punctuation">(</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>L2<span class="token punctuation">(</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="optimize优化-减少误差" tabindex="-1"><a class="header-anchor" href="#optimize优化-减少误差"><span>Optimize优化 - 减少误差</span></a></h3><p>（这章P67 3.4我其实不太看得懂）</p><p>先引一个东西：数字舍入误差（numerical roundoff error）</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x1 <span class="token operator">=</span> <span class="token number">2.0</span><span class="token operator">/</span><span class="token number">10000</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>x1<span class="token punctuation">:</span><span class="token format-spec">.18f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>	<span class="token comment"># 保留18位小数</span>
<span class="token comment"># 输出：0.000200000000000000</span>

x2 <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">+</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">10000</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>x1<span class="token punctuation">:</span><span class="token format-spec">.18f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>	<span class="token comment"># 保留18位小数</span>
<span class="token comment"># 输出：0.000199999999999978</span>

<span class="token comment"># 为了减少这些误差，在TensorFlow进行更准确的计算，原理是可以将1/10000看作一个中间量</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>神经网络中的代码优化如下</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># 将</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss <span class="token operator">=</span> SparseCategoricalCrossentropy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 替换成</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss <span class="token operator">=</span> SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>原理是</p>`,28)),a[153]||(a[153]=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mtext",null,"将"),s("mspace",{linebreak:"newline"}),s("mrow",null,[s("mo",{fence:"true"},"{"),s("mtable",{rowspacing:"0.36em",columnalign:"left left",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",null,"a"),s("mo",null,"="),s("mi",null,"g"),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"z")])])])])])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mi",null,"L"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"s"),s("mo",null,"="),s("mo",null,"−"),s("mi",null,"y"),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"y"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"a"),s("mo",{stretchy:"false"},")")])])])])])]),s("mspace",{linebreak:"newline"}),s("mtext",null,"变成"),s("mspace",{linebreak:"newline"}),s("mi",null,"L"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"s"),s("mo",null,"="),s("mo",null,"−"),s("mi",null,"y"),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"z")])])])]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"y"),s("mo",{stretchy:"false"},")"),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"z")])])])]),s("mo",{stretchy:"false"},")"),s("mspace",{linebreak:"newline"})]),s("annotation",{encoding:"application/x-tex"}," 将\\\\ \\begin{cases} a=g(z)=\\frac1{1+e^{-z}}\\\\ Loss=-y\\log (a)-(1-y)\\log(1-a)\\\\ \\end{cases}\\\\ 变成\\\\ Loss=-y\\log (\\frac1{1+e^{-z}})-(1-y)\\log(1-\\frac1{1+e^{-z}})\\\\ ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord cjk_fallback"},"将")]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3em","vertical-align":"-1.25em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.69em"}},[s("span",{style:{top:"-3.69em"}},[s("span",{class:"pstrut",style:{height:"3.008em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7027em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4033em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-2.25em"}},[s("span",{class:"pstrut",style:{height:"3.008em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"oss"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[l("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[l("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.19em"}},[s("span")])])])])])]),s("span",{class:"mclose nulldelimiter"})])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord cjk_fallback"},"变成")]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"oss"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0908em","vertical-align":"-0.7693em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[l("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6973em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[l("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0908em","vertical-align":"-0.7693em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6973em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")")]),s("span",{class:"mspace newline"})])])])],-1)),a[154]||(a[154]=n(`<h3 id="optimize优化-adam优化算法" tabindex="-1"><a class="header-anchor" href="#optimize优化-adam优化算法"><span>Optimize优化 - AdaM优化算法</span></a></h3><p>概念</p><p>AdaM算法直觉（AdaM Algorithm Intuition） 其中AdaM含义为：自适应估算方法（AdaM，Adaptive Moment estimation）</p><p>我们知道梯度下降法需要设置学习率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>，学习率过大会导致无法收敛、过小会导致收敛速度太慢。 而该算法能够动态自动调节<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>，刚开始时快速下降，收敛时速度减慢</p><p>大概原理</p><p>当往一个方向下降时，增大<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\\alpha_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>。当发现<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>来回正当时，减低<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\\alpha_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></p><p>代码写法</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;sigmoid&#39;</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&#39;linear&#39;</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning<span class="token operator">-</span>rate<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>		 <span class="token comment"># 指定优化器（使用Adam算法优化，初始学习率为10^-3）</span>
    loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,8))])}const ht=o(w,[["render",ct],["__file","01. 神经网络.html.vue"]]),dt=JSON.parse('{"path":"/MdNote_Public/01.%20DesignAndDevelop/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/01.%20%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02.%20%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/01.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html","title":"吴恩达机器学习","lang":"zh-CN","frontmatter":{"description":"吴恩达机器学习 目录 第二课导读 神经网络（Neural Networks） 推理（预言） 训练 建立机器学习系统的一些实用建议 决策树（Decision Tree） 神经网络（Neural Networks） 入门 入门 起源 模拟神经元和大脑（Neuron & Brain） 研究历史 起源：1950年尝试去模拟大脑 1980~1990年，再次流行 ...","head":[["meta",{"property":"og:url","content":"https://LincZero.github.io/MdNote_Public/01.%20DesignAndDevelop/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/01.%20%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02.%20%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/01.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"吴恩达机器学习"}],["meta",{"property":"og:description","content":"吴恩达机器学习 目录 第二课导读 神经网络（Neural Networks） 推理（预言） 训练 建立机器学习系统的一些实用建议 决策树（Decision Tree） 神经网络（Neural Networks） 入门 入门 起源 模拟神经元和大脑（Neuron & Brain） 研究历史 起源：1950年尝试去模拟大脑 1980~1990年，再次流行 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"LincZero"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"吴恩达机器学习\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"吴恩达机器学习","slug":"吴恩达机器学习","link":"#吴恩达机器学习","children":[]},{"level":1,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":1,"title":"神经网络（Neural Networks）","slug":"神经网络-neural-networks","link":"#神经网络-neural-networks","children":[{"level":2,"title":"入门","slug":"入门","link":"#入门","children":[{"level":3,"title":"入门","slug":"入门-1","link":"#入门-1","children":[{"level":4,"title":"起源","slug":"起源","link":"#起源","children":[]},{"level":4,"title":"神经网络为何如此高效","slug":"神经网络为何如此高效","link":"#神经网络为何如此高效","children":[]}]},{"level":3,"title":"概念","slug":"概念","link":"#概念","children":[{"level":4,"title":"激活函数（Activation Function）","slug":"激活函数-activation-function","link":"#激活函数-activation-function","children":[]},{"level":4,"title":"神经元（Neuron）/ 单元（Units）","slug":"神经元-neuron-单元-units","link":"#神经元-neuron-单元-units","children":[]},{"level":4,"title":"层（Layer）","slug":"层-layer","link":"#层-layer","children":[]},{"level":4,"title":"神经网络（Neural Networks）","slug":"神经网络-neural-networks-1","link":"#神经网络-neural-networks-1","children":[]}]},{"level":3,"title":"使用举例","slug":"使用举例","link":"#使用举例","children":[{"level":4,"title":"举例 - 需求预测（Demand Prediction）","slug":"举例-需求预测-demand-prediction","link":"#举例-需求预测-demand-prediction","children":[]},{"level":4,"title":"举例 - 图像感知、物品识别","slug":"举例-图像感知、物品识别","link":"#举例-图像感知、物品识别","children":[]}]}]},{"level":2,"title":"前向传播（Forward Propagation）","slug":"前向传播-forward-propagation","link":"#前向传播-forward-propagation","children":[{"level":3,"title":"概念","slug":"概念-1","link":"#概念-1","children":[]},{"level":3,"title":"公式","slug":"公式","link":"#公式","children":[]},{"level":3,"title":"代码基础","slug":"代码基础","link":"#代码基础","children":[{"level":4,"title":"NumPy中数据的形式","slug":"numpy中数据的形式","link":"#numpy中数据的形式","children":[]},{"level":4,"title":"Tensorflow中数据形式","slug":"tensorflow中数据形式","link":"#tensorflow中数据形式","children":[]}]},{"level":3,"title":"代码实现","slug":"代码实现","link":"#代码实现","children":[{"level":4,"title":"举例 - 手写体数字识别","slug":"举例-手写体数字识别","link":"#举例-手写体数字识别","children":[]},{"level":4,"title":"举例 - 判断咖啡是否煮得好","slug":"举例-判断咖啡是否煮得好","link":"#举例-判断咖啡是否煮得好","children":[]}]},{"level":3,"title":"代码原理","slug":"代码原理","link":"#代码原理","children":[{"level":4,"title":"未矩阵化","slug":"未矩阵化","link":"#未矩阵化","children":[]},{"level":4,"title":"矩阵化","slug":"矩阵化","link":"#矩阵化","children":[]}]}]},{"level":2,"title":"训练（Model Training）","slug":"训练-model-training","link":"#训练-model-training","children":[{"level":3,"title":"代码实现","slug":"代码实现-1","link":"#代码实现-1","children":[]},{"level":3,"title":"训练的三个步骤","slug":"训练的三个步骤","link":"#训练的三个步骤","children":[{"level":4,"title":"① 定义模型、定义层与激活函数","slug":"_1-定义模型、定义层与激活函数","link":"#_1-定义模型、定义层与激活函数","children":[]},{"level":4,"title":"② 定义Loss函数、Cost函数","slug":"_2-定义loss函数、cost函数","link":"#_2-定义loss函数、cost函数","children":[]},{"level":4,"title":"③ 最优化、模型训练","slug":"_3-最优化、模型训练","link":"#_3-最优化、模型训练","children":[]}]},{"level":3,"title":"训练的三个步骤 - 具体","slug":"训练的三个步骤-具体","link":"#训练的三个步骤-具体","children":[{"level":4,"title":"公式中","slug":"公式中","link":"#公式中","children":[]},{"level":4,"title":"逻辑回归中","slug":"逻辑回归中","link":"#逻辑回归中","children":[]},{"level":4,"title":"神经网络中","slug":"神经网络中","link":"#神经网络中","children":[]}]}]},{"level":2,"title":"神经网络的优化方法","slug":"神经网络的优化方法","link":"#神经网络的优化方法","children":[{"level":3,"title":"Model优化 - 正则化","slug":"model优化-正则化","link":"#model优化-正则化","children":[]},{"level":3,"title":"Optimize优化 - 减少误差","slug":"optimize优化-减少误差","link":"#optimize优化-减少误差","children":[]},{"level":3,"title":"Optimize优化 - AdaM优化算法","slug":"optimize优化-adam优化算法","link":"#optimize优化-adam优化算法","children":[]}]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":10.35,"words":3106},"filePathRelative":"MdNote_Public/01. DesignAndDevelop/Develop/04. Project/Type/Artificial_Intelligence/线性型/01. 吴恩达 机器学习/02. 高级学习算法/01. 神经网络.md","excerpt":"\\n<h1>目录</h1>\\n<p>第二课导读</p>\\n<ul>\\n<li>神经网络（Neural Networks）\\n<ul>\\n<li>推理（预言）</li>\\n<li>训练</li>\\n</ul>\\n</li>\\n<li>建立机器学习系统的一些实用建议</li>\\n<li>决策树（Decision Tree）</li>\\n</ul>\\n<h1>神经网络（Neural Networks）</h1>\\n<h2>入门</h2>\\n<h3>入门</h3>\\n<h4>起源</h4>\\n<p>模拟神经元和大脑（Neuron &amp; Brain）</p>\\n<p>研究历史</p>\\n<ul>\\n<li>起源：1950年尝试去模拟大脑</li>\\n<li>1980~1990年，再次流行</li>\\n<li>2005年，兴起</li>\\n<li>神经网络近期增长，也很大程度因为数据的数量多了很多，即大数据。这得以去训练大型神经网络</li>\\n</ul>","autoDesc":true}');export{ht as comp,dt as data};
