import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as i,c as l,a as t,b as e,d as a}from"./app-5ajJQ-aM.js";const s="/assets/image-20221103121731785-BToYvnNl.png",o="/assets/image-20221103122609639-8HSwFhhK.png",r="/assets/image-20221103123240900-rQGpljeq.png",p="/assets/image-20221103134557737-B2jjiBcp.png",c="/assets/image-20221103153319895-Dd9ONhjT.png",g="/assets/image-20221103153456455-BJMLF9fH.png",d="/assets/image-20221103141809443-DPXpi_e1.png",h="/assets/image-20221103150519784-DKSnd_i1.png",u="/assets/image-20221103150903926-Dr_E_7-K.png",m="/assets/image-20221103153823066-DaHxcJWQ.png",f={},N=t('<h1 id="李宏毅机器学习深度学习" tabindex="-1"><a class="header-anchor" href="#李宏毅机器学习深度学习"><span>李宏毅机器学习深度学习</span></a></h1><h1 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h1><h1 id="cnn-convolutional-neural-network" tabindex="-1"><a class="header-anchor" href="#cnn-convolutional-neural-network"><span>CNN（Convolutional Neural Network）</span></a></h1><p>对应视频：P31 对应pdf：09_CNN.pdf</p><h2 id="图片分类" tabindex="-1"><a class="header-anchor" href="#图片分类"><span>图片分类</span></a></h2><h3 id="参数量爆炸" tabindex="-1"><a class="header-anchor" href="#参数量爆炸"><span>参数量爆炸</span></a></h3><p>是怎麼把一张影像当做一个模型的输入 对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量） 如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的矩阵就是 Tensor</p><figure><img src="'+s+'" alt="image-20221103121731785" tabindex="0" loading="lazy"><figcaption>image-20221103121731785</figcaption></figure><p>一些翻译：</p><ul><li>Tensor，[数] 张量</li><li>channels，通道</li><li>pattern，模式、图案</li><li>Receptive Field，感受野、接受野、卷积野</li></ul><p>如果全连接（Fully Connected）</p><blockquote><p>虽然随著参数的增加,我们可以增加模型的弹性,我们可以增加它的能力,但是我们也增加了 Overfitting 的风 险,有关什麼叫模型的弹性,到底 Overfitting 怎麼產生的,下週吴培元老师https://speech.ee.ntu.edu.tw/~hyle e/ml/ml2021-course-data/W14_PAC-introduction.pdf会从数学上,给大家非常清楚的证明,那我们这边就讲 概念上,如果模型的弹性越大,就越容易 Overfitting</p></blockquote><h3 id="解决方法" tabindex="-1"><a class="header-anchor" href="#解决方法"><span>解决方法</span></a></h3><p>两种简化的方法</p><h4 id="感受野" tabindex="-1"><a class="header-anchor" href="#感受野"><span>感受野</span></a></h4><p>Pattern检测、感受野</p><blockquote><p>是判断说现在有没有某种 Pattern 出现时，我们并不需要每 一个 Neuron都去看一张完整的图片</p><p>所以这些 Neuron 也许根本就不需要,把整张图片当作输入,它们只需要把图片的一小部分当作输入,就足以让 它们侦测某些特别关键的 Pattern有没有出现了</p><p>我们会设定一个区域叫做 <strong>Receptive Field（感受野、接受野、卷积野）</strong>,每一个 Neuron 都只关心自己的 Receptive Field 裡面发生的事情就好了</p></blockquote><p>一些想法：</p><ul><li>我可不可以 Receptive Field 有大有小呢？可以</li><li>我可不可以 Receptive Field,只考虑某些 Channel 呢？可以</li><li>可不可以是长方形？可以！</li><li>Receptive Field 一定要相连吗？理论上可以，但是这种特征应该很少见，二维码区域识别应该算</li></ul><figure><img src="'+o+'" alt="image-20221103122609639" tabindex="0" loading="lazy"><figcaption>image-20221103122609639</figcaption></figure><p>一些概念</p><ul><li>Kernel Size（核尺寸） <ul><li>我们在描述一个 Receptive Field 的时候,只要讲它的高跟宽就好了。 就不用讲它的深度，反正深度一定是考虑全部的 Channel。 而这个高跟宽合起来叫做 Kernel Size</li><li>一般3x3，也有5x5，7x7</li></ul></li><li>Stride（步幅） <ul><li>Stride 是一个你自己决定的 Hyperparameter,但这个 Stride 你往往 不会设太大,往往设 1 或 2 就可以了</li><li>超出的就不要，或者做padding</li></ul></li><li>Padding（填充，补值）</li></ul><h4 id="共享参数" tabindex="-1"><a class="header-anchor" href="#共享参数"><span>共享参数</span></a></h4><p>同样的 Pattern，它可能会出现在图片的不同区域裡面</p><p>我们真的需要每一个守备范围,都去放一个侦测鸟嘴的 Neuron 吗？不需要！</p><p>放在影像处理上的话,我们能不能够让,不同 Receptive Field 的 Neuron共享参数,也就是做 Parameter Sharing权值共享</p><figure><img src="'+r+'" alt="image-20221103123240900" tabindex="0" loading="lazy"><figcaption>image-20221103123240900</figcaption></figure><p>位置不同但可以使用相同的权重！</p><p>具体上，怎么去共享参数？</p><p>你完全可以自己决定，而这个是你可以自己决定的事情，但是接下来还是要告诉大家，常见的在影像辨识上面的共享的方法,是怎麼设定的</p><p>实每一个 Receptive Field都只有一组参数而已，那这些参数有一个名字，叫做 <strong>Filter（卷积核、过滤器、滤波器</strong>）</p><figure><img src="'+p+'" alt="image-20221103134557737" tabindex="0" loading="lazy"><figcaption>image-20221103134557737</figcaption></figure><h4 id="pooling-池化层" tabindex="-1"><a class="header-anchor" href="#pooling-池化层"><span>Pooling 池化层</span></a></h4><p>把一张大的图片缩小，这是一隻鸟，这张小的图片看起来还是一隻鸟</p><figure><img src="'+c+'" alt="image-20221103153319895" tabindex="0" loading="lazy"><figcaption>image-20221103153319895</figcaption></figure><p>Pooling 这个东西啊,它本身没有参数,所以它不是一个 Layer,它裡面没有 Weight,它没有要 Learn 的东西</p><p>所以 有人会告诉你说 Pooling 比较像是一个 Activation Function,比较像是 Sigmoid ， ReLU 那些,因為它裡面是 没有要 Learn 的东西的,它就是一个 Operator,它的行為都是固定好的,没有要根据 Data 学任何东西</p><p>Pooling 其实也有很多不同的版本,我们这边讲的是 Max Pooling</p><blockquote><h5 id="maxpooling" tabindex="-1"><a class="header-anchor" href="#maxpooling"><span>MaxPooling</span></a></h5></blockquote><figure><img src="'+g+'" alt="image-20221103153456455" tabindex="0" loading="lazy"><figcaption>image-20221103153456455</figcaption></figure><p>在这个例子 裡面就是 2×2 个一组,每一组裡面选一个代表,在 Max Pooling 裡面,我们选的代表就是最大的那一个</p><p><strong>一般在实际上，Convolution和Pooling会交替使用</strong></p><p>Pooling会带来一点图片损耗，最近运算能力越来越强，有的网络的设计甚至不用Pooling，Full Convolution</p><h3 id="整理总结" tabindex="-1"><a class="header-anchor" href="#整理总结"><span>整理总结</span></a></h3><figure><img src="'+d+'" alt="image-20221103141809443" tabindex="0" loading="lazy"><figcaption>image-20221103141809443</figcaption></figure><p>我们加了 <strong>感受野</strong> 和 <strong>参数共享</strong> 来限制全连接，变成卷积层 CNN。</p><p>CNN 的弹性小了很多，Bias 比较大 可能有小伙伴会说 Model Bias 比较大 不是一件坏事吗？ Model Bias 大，不一定是坏事</p><ul><li>因為当 Model Bias 小，Model 的 Flexibility 很高的时候，它比较容易 Overfitting。</li><li>虽然Fully Connected Layer可以做各式各样的事情，它可以有各式各样的变化，但是它可能没有办法在任何特定的任务上做好</li><li>Convolutional Layer它是专门為影像设计的。刚才讲的 Receptive Field 参数共享，这些观察 都是為影像设计的，所以它在影像上仍然可以做得好。 虽然它的 Model Bias 很大，但这个在影像上不是问题。但是如果它用在影像之外的任务，你就要仔细想想那些任务有没有我们刚才讲的影像用的特性</li></ul><h2 id="卷积层" tabindex="-1"><a class="header-anchor" href="#卷积层"><span>卷积层</span></a></h2><p>Convolutional 的 Layer 就是裡面有很多的 Filter</p><p>一个 Convolutional 的 Layer 裡面就是有一排的 Filter，一个 Filter 的作用就是要去图片裡面某一个 Pattern</p><h3 id="卷积操作、特征图谱" tabindex="-1"><a class="header-anchor" href="#卷积操作、特征图谱"><span>卷积操作、特征图谱</span></a></h3><p>把 Filter 裡面所有的值,跟左上角这个范围内的 9 个值做相乘,也就是把这个 Filter 裡面的 9 个值,跟这个范围裡 面的 9 个值呢,做 Inner Product,做完是 3</p><p>注意！在此处卷集运算中，老师讲的内积，不要理解为线性代数中矩阵的乘法，而是filter跟图片对应位置的 数值直接相乘，所有的都乘完以后再相加</p><figure><img src="'+h+'" alt="image-20221103150519784" tabindex="0" loading="lazy"><figcaption>image-20221103150519784</figcaption></figure><p>假设有64个过滤器，那么我们就得到 64 群的数字了。 这一群数字啊，它又有一个名字，它叫做 <strong>Feature Map（特征图谱）</strong></p><p>如果我们的 Filter 的大小一直设 3 × 3,会不会让我们的 Network,没有办法看比较大范围的 Pattern 呢？不会</p><p>例如当我们看这 3 × 3 的范围的Feature Map时候，其实是考虑了一个 5 × 5 的范围</p><figure><img src="'+u+'" alt="image-20221103150903926" tabindex="0" loading="lazy"><figcaption>image-20221103150903926</figcaption></figure><p>所以 Network 够深,你不用怕你侦测不到比较 大的 Pattern,它还是可以侦测到比较大的 Pattern</p><h3 id="整个cnn" tabindex="-1"><a class="header-anchor" href="#整个cnn"><span>整个CNN</span></a></h3><figure><img src="'+m+'" alt="image-20221103153823066" tabindex="0" loading="lazy"><figcaption>image-20221103153823066</figcaption></figure><h2 id="怎么使用cnn下围棋" tabindex="-1"><a class="header-anchor" href="#怎么使用cnn下围棋"><span>怎么使用CNN下围棋？</span></a></h2>',63),_=e("p",null,[a("可以将棋盘表示成一个"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mn",null,"19"),e("mo",null,"×"),e("mn",null,"19")]),e("annotation",{encoding:"application/x-tex"},"19\\times 19")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),e("span",{class:"mord"},"19"),e("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),e("span",{class:"mbin"},"×"),e("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6444em"}}),e("span",{class:"mord"},"19")])])]),a("的二维向量作为输入，然后可以变成一个"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mn",null,"19"),e("mo",null,"×"),e("mn",null,"19")]),e("annotation",{encoding:"application/x-tex"},"19\\times 19")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),e("span",{class:"mord"},"19"),e("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),e("span",{class:"mbin"},"×"),e("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6444em"}}),e("span",{class:"mord"},"19")])])]),a("的多分类问题")],-1),E=e("p",null,"CNN会比Fully-connected的效果更好。AlphaGo的原始论文里说，每一个Pixel，它是用 48 个 Channel 来 描述",-1),x=e("p",null,"有一点与图像识别不同：",-1),v=e("blockquote",null,[e("p",null,"在做影像的时候我们说我们都会做 Pooling，一张影像做 Subsampling 以后, 并不会影响我们对影像中物件的判读"),e("p",null,"但是棋盘是这个样子吗？你可以把棋盘上的奇数行跟偶数列拿掉，还是同一个棋局吗？ 下围棋这麼精细的任务,你随便拿掉一个 Column 拿掉一个 Row，整个棋整个局势就不一样了")],-1),A=e("h2",{id:"局限性",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#局限性"},[e("span",null,"局限性")])],-1),b=e("p",null,"CNN，没有办法处理影像放大缩小，或者是旋转的问题",-1),C=e("p",null,"那就是為什麼在做影像辨识的时候，往往都要做 Data Augmentation",-1),y=[N,_,E,x,v,A,b,C];function k(B,F){return i(),l("div",null,y)}const M=n(f,[["render",k],["__file","01. CNN.html.vue"]]),D=JSON.parse('{"path":"/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/02.%20%E6%9D%8E%E5%AE%8F%E6%AF%85%202020%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03.%20CNN/01.%20CNN.html","title":"李宏毅机器学习深度学习","lang":"zh-CN","frontmatter":{"description":"李宏毅机器学习深度学习 目录 CNN（Convolutional Neural Network） 对应视频：P31 对应pdf：09_CNN.pdf 图片分类 参数量爆炸 是怎麼把一张影像当做一个模型的输入 对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量） 如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的...","head":[["meta",{"property":"og:url","content":"http://192.168.0.101:8080/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/02.%20%E6%9D%8E%E5%AE%8F%E6%AF%85%202020%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03.%20CNN/01.%20CNN.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"李宏毅机器学习深度学习"}],["meta",{"property":"og:description","content":"李宏毅机器学习深度学习 目录 CNN（Convolutional Neural Network） 对应视频：P31 对应pdf：09_CNN.pdf 图片分类 参数量爆炸 是怎麼把一张影像当做一个模型的输入 对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量） 如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"LincZero"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"李宏毅机器学习深度学习\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"李宏毅机器学习深度学习","slug":"李宏毅机器学习深度学习","link":"#李宏毅机器学习深度学习","children":[]},{"level":1,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":1,"title":"CNN（Convolutional Neural Network）","slug":"cnn-convolutional-neural-network","link":"#cnn-convolutional-neural-network","children":[{"level":2,"title":"图片分类","slug":"图片分类","link":"#图片分类","children":[{"level":3,"title":"参数量爆炸","slug":"参数量爆炸","link":"#参数量爆炸","children":[]},{"level":3,"title":"解决方法","slug":"解决方法","link":"#解决方法","children":[{"level":4,"title":"感受野","slug":"感受野","link":"#感受野","children":[]},{"level":4,"title":"共享参数","slug":"共享参数","link":"#共享参数","children":[]},{"level":4,"title":"Pooling 池化层","slug":"pooling-池化层","link":"#pooling-池化层","children":[]}]},{"level":3,"title":"整理总结","slug":"整理总结","link":"#整理总结","children":[]}]},{"level":2,"title":"卷积层","slug":"卷积层","link":"#卷积层","children":[{"level":3,"title":"卷积操作、特征图谱","slug":"卷积操作、特征图谱","link":"#卷积操作、特征图谱","children":[]},{"level":3,"title":"整个CNN","slug":"整个cnn","link":"#整个cnn","children":[]}]},{"level":2,"title":"怎么使用CNN下围棋？","slug":"怎么使用cnn下围棋","link":"#怎么使用cnn下围棋","children":[]},{"level":2,"title":"局限性","slug":"局限性","link":"#局限性","children":[]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":6.39,"words":1918},"filePathRelative":"MdNote_Public/01. 设计开发与数据生产/Develop/04. Project/Type/Artificial_Intelligence/线性型/02. 李宏毅 2020机器学习深度学习/03. CNN/01. CNN.md","autoDesc":true}');export{M as comp,D as data};
