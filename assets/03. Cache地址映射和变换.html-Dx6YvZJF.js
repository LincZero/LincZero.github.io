import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as t,c as n,e as s,a,b as l}from"./app-DErOheJD.js";const c="/assets/Image00074-26aKsVpZ.jpg",i="/assets/Image00077-4tEOyegZ.jpg",p="/assets/Image00081-DGDFOgra.jpg",r={},m=s('<h1 id="cache地址映射和变换" tabindex="-1"><a class="header-anchor" href="#cache地址映射和变换"><span>Cache地址映射和变换</span></a></h1><p>这章的重点是：<strong>Cache和内存的 数据交换</strong>，关系Cache和内存的读写。</p><h2 id="底层细节和术语" tabindex="-1"><a class="header-anchor" href="#底层细节和术语"><span>底层细节和术语</span></a></h2><p>为了进行Cache和内存的数据交换，这里介绍一点底层细节和术语：</p><h3 id="分块机制" tabindex="-1"><a class="header-anchor" href="#分块机制"><span>分块机制</span></a></h3><p>这里的分“块”指的“块”也叫“CacheLine”，Cache和内存以块为单位进行数据交换，块的大小通常以在内存的一个存储周期中能够访问到的数据长度为限。</p><div class="hint-container note"><p class="hint-container-title">注</p><p>(GPT) 术语：<strong>Cache Line (缓存行)</strong></p><ul><li>概念：缓存行是内存中基本单位/<strong>最小的数据单位，它可以被加载到缓存中</strong>。</li><li>包含内容：一个缓存行通常包含： <ul><li>实际的数据</li><li>一些元数据（例如有效位、脏位、共享状态等）</li></ul></li><li>大小：是最小数据单位。且其大小通常是固定的，并且因不同的处理器架构而异。常见的有： <ul><li>32字节： 较早的ARM、1990年~2000年早期的x86和PowerPC</li><li>64字节： 较新的ARM和x86</li><li>128字节： 较新的Power ISA机器</li></ul></li><li><strong>机制 - 整个加载以利用局部性原理</strong>：每次从主内存读取数据时，不仅仅是请求的特定字节会被加载，而是整个缓存行都会被加载到缓存中。 这样做的目的是为了利用局部性原理（Locality Principle），即程序往往连续访问内存中的数据或在短时间内重复访问相同的数据。</li><li><strong>机制 - 缓存行对齐以确保高效加载</strong>：数据在内存中的位置需要与缓存行边界对齐</li></ul></div><div class="hint-container note"><p class="hint-container-title">注</p><p>(GPT) 术语：<strong>Cache Entry (缓存条目)</strong></p><ul><li><p>概念：缓存条目是指缓存中用于存储数据的一个<strong>位置</strong>。</p></li><li><p>被组织方式：缓存可以按照多种方式组织缓存条目：</p><ul><li>直接映射（Direct Mapped）</li><li>全相联（Fully Associative）</li><li>组相联（Set Associative）</li></ul></li><li><p>包含内容：每个缓存条目通常包括：</p><ul><li>数据部分（Data）</li><li>标记部分（Tag）</li><li>控制信息（如有效位、脏位等）</li></ul><p>另外。一个缓存条目可以包含一个或多个缓存行，具体取决于缓存的设计。</p></li><li><p>机制 - 替换策略：当缓存满了需要加载新数据时，会根据某种替换策略来决定哪个缓存条目将被替换掉，常见的策略有：</p><ul><li>LRU（Least Recently Used 最近最少使用）</li><li>FIFO（First In First Out 先进先出</li><li>等</li></ul></li></ul></div><h3 id="映射算法" tabindex="-1"><a class="header-anchor" href="#映射算法"><span>映射算法</span></a></h3><p>而映射算法是指<strong>把内存地址空间映射到Cache地址空间</strong>。</p><p>具体来说，就是把存放在内存中的内容按照某种规则装入到Cache中，并建立内存地址与Cache地址之间的对应关系。当内容已经装入到Cache之后，在实际运行过程中，当处理器需要访问这个数据块内容时，则需要<strong>把内存地址转换成Cache地址，从而在Cache中找到该数据块，最终返回给处理器</strong>。</p><h2 id="三类cache-粗" tabindex="-1"><a class="header-anchor" href="#三类cache-粗"><span>三类Cache (粗)</span></a></h2><p>三类Cache</p><p>根据Cache和内存之间的映射关系的不同，Cache可以分为三类：</p><ul><li>第一类：全关联型 Cache（full associative cache）</li><li>第二类：直接关联型 Cache（direct mapped cache）</li><li>第三类：组关联型 Cache（N-ways associative cache）</li></ul><h3 id="提前总结、比较" tabindex="-1"><a class="header-anchor" href="#提前总结、比较"><span>提前总结、比较</span></a></h3><p>共同点：</p><ul><li>无论哪种都会在Cache中建立一个目录表，根据不同的映射方案，目录表内容不同</li></ul><p>不同点：</p><table><thead><tr><th></th><th>全关联型Cache</th><th>直接关联型Cache</th><th>组关联型Cache</th></tr></thead><tbody><tr><td>目录表</td><td>内存地址<br>Cache块号<br>有效位</td><td>区号<br>_<br>有效位</td><td>“区号+块号”<br>Cache块号<br>有效位</td></tr><tr><td>映射数</td><td></td><td></td><td></td></tr><tr><td>优点</td><td>无块冲突，利用率高</td><td>实现简单，匹配快</td><td>(各取所长)</td></tr><tr><td>缺点</td><td>大容量导致电路设计复杂</td><td>Cache命中率低</td><td></td></tr><tr><td>选用</td><td>小容量Cache</td><td></td><td></td></tr></tbody></table><h3 id="全关联型cache-full-associative-cache" tabindex="-1"><a class="header-anchor" href="#全关联型cache-full-associative-cache"><span>全关联型Cache（full associative cache）</span></a></h3><ul><li><p>特点：全关联型Cache是指主存中的<em>任何一块内存都可以映射到Cache中的任意一块位置上</em>。</p></li><li><p>原理 - 目录表：三部分组成：</p><ul><li>内存地址</li><li>Cache块号</li><li>有效位</li></ul></li><li><p>原理 - 查找：</p><p>当处理器需要访问某个内存地址时，首先通过该目录表查询是否该内容缓存在Cache中，具体过程如下图所示：</p><figure><img src="'+c+'" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>首先，用内存的块地址A在Cache的目录表中进行查询，如果找到等值的内存块地址，检查有效位是否有效</p><ul><li>有效的情况下，能通过Cache块号在Cache中找到缓存的内存，并且加上块内地址B，找到相应数据，这时则称为<strong>Cache命中</strong>，处理器拿到数据返回；</li><li>否则为<strong>Cache Miss</strong>，处理器则需要在内存中读取相应的数据。</li></ul></li><li><p>优点：块的冲突最小（没有冲突），Cache的利用率也高，但是需要一个访问速度很快的相联存储器。</p></li><li><p>缺点：随着Cache容量的增加，其电路设计变得十分复杂</p></li><li><p>场景：因此只有容量很小的Cache才会设计成全关联型的（如一些英特尔处理器中的TLB Cache）</p></li></ul><h3 id="直接关联型cache-direct-mapped-cache" tabindex="-1"><a class="header-anchor" href="#直接关联型cache-direct-mapped-cache"><span>直接关联型Cache（direct mapped cache）</span></a></h3>',23),h=a("ul",null,[a("li",null,[a("p",null,[l("特点：直接关联型Cache是指主存中的"),a("em",null,"一块内存只能映射到Cache的一个特定的块中"),l("。")]),a("p",null,[l("假设一个Cache中总共存在N个Cache line，那么内存被分成N等分，其中每一等分对应一个Cache line。举个简单的例子，假设Cache的大小是2K，而一个Cache line的大小是64B，那么就一共有 "),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mn",null,"2"),a("mi",null,"K"),a("mi",{mathvariant:"normal"},"/"),a("mn",null,"64"),a("mi",null,"B"),a("mo",null,"="),a("mn",null,"32"),a("mtext",null,"个")]),a("annotation",{encoding:"application/x-tex"},"2K/64B=32个")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mord"},"2"),a("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),a("span",{class:"mord"},"/64"),a("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"="),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6833em"}}),a("span",{class:"mord"},"32"),a("span",{class:"mord cjk_fallback"},"个")])])]),l(" Cache line，那么对应我们的这些内存：")]),a("p",{class:"katex-block"},[a("span",{class:"katex-display"},[a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[a("semantics",null,[a("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[a("mtr",null,[a("mtd",{class:"mtr-glue"}),a("mtd",null,[a("mstyle",{scriptlevel:"0",displaystyle:"true"},[a("mrow",null,[a("mtext",null,"第 "),a("mn",null,"1"),a("mtext",null,"块 地址：")])])]),a("mtd",null,[a("mstyle",{scriptlevel:"0",displaystyle:"true"},[a("mrow",null,[a("mrow"),a("mn",null,"0"),a("mo",null,"∼"),a("mn",null,"63")])])]),a("mtd",{class:"mtr-glue"}),a("mtd",{class:"mml-eqn-num"})]),a("mtr",null,[a("mtd",{class:"mtr-glue"}),a("mtd",null,[a("mstyle",{scriptlevel:"0",displaystyle:"true"},[a("mrow",null,[a("mtext",null,"第"),a("mn",null,"33"),a("mtext",null,"块 地址：")])])]),a("mtd",null,[a("mstyle",{scriptlevel:"0",displaystyle:"true"},[a("mrow",null,[a("mrow"),a("mn",null,"64"),a("mo",null,"∗"),a("mn",null,"32"),a("mo",null,"∼"),a("mn",null,"64"),a("mo",null,"∗"),a("mn",null,"33"),a("mo",null,"−"),a("mn",null,"1")])])]),a("mtd",{class:"mtr-glue"}),a("mtd",{class:"mml-eqn-num"})]),a("mtr",null,[a("mtd",{class:"mtr-glue"}),a("mtd",null,[a("mstyle",{scriptlevel:"0",displaystyle:"true"},[a("mrow",null,[a("mtext",null,"第"),a("mo",{stretchy:"false"},"("),a("mi",null,"N"),a("mo",null,"∗"),a("mn",null,"32"),a("mo",null,"+"),a("mn",null,"1"),a("mo",{stretchy:"false"},")"),a("mtext",null,"块 地址：")])])]),a("mtd",null,[a("mstyle",{scriptlevel:"0",displaystyle:"true"},[a("mrow",null,[a("mrow"),a("mn",null,"64"),a("mo",null,"∗"),a("mo",{stretchy:"false"},"("),a("mi",null,"N"),a("mo",null,"−"),a("mn",null,"1"),a("mo",{stretchy:"false"},")"),a("mo",null,"∼"),a("mn",null,"64"),a("mo",null,"∗"),a("mi",null,"N"),a("mo",null,"−"),a("mn",null,"1")])])]),a("mtd",{class:"mtr-glue"}),a("mtd",{class:"mml-eqn-num"})])]),a("annotation",{encoding:"application/x-tex"}," \\begin{align} 第~1块~地址：& 0\\sim63\\\\ 第33块~地址：& 64*32\\sim64*33-1\\\\ 第(N*32+1)块~地址：& 64*(N-1)\\sim 64*N-1\\\\ \\end{align} ")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"4.5em","vertical-align":"-2em"}}),a("span",{class:"mtable"},[a("span",{class:"col-align-r"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"2.5em"}},[a("span",{style:{top:"-4.66em"}},[a("span",{class:"pstrut",style:{height:"3em"}}),a("span",{class:"mord"},[a("span",{class:"mord cjk_fallback"},"第"),a("span",{class:"mspace nobreak"}," "),a("span",{class:"mord"},"1"),a("span",{class:"mord cjk_fallback"},"块"),a("span",{class:"mspace nobreak"}," "),a("span",{class:"mord cjk_fallback"},"地址：")])]),a("span",{style:{top:"-3.16em"}},[a("span",{class:"pstrut",style:{height:"3em"}}),a("span",{class:"mord"},[a("span",{class:"mord cjk_fallback"},"第"),a("span",{class:"mord"},"33"),a("span",{class:"mord cjk_fallback"},"块"),a("span",{class:"mspace nobreak"}," "),a("span",{class:"mord cjk_fallback"},"地址：")])]),a("span",{style:{top:"-1.66em"}},[a("span",{class:"pstrut",style:{height:"3em"}}),a("span",{class:"mord"},[a("span",{class:"mord cjk_fallback"},"第"),a("span",{class:"mopen"},"("),a("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"∗"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"32"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"+"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"1"),a("span",{class:"mclose"},")"),a("span",{class:"mord cjk_fallback"},"块"),a("span",{class:"mspace nobreak"}," "),a("span",{class:"mord cjk_fallback"},"地址：")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"2em"}},[a("span")])])])]),a("span",{class:"col-align-l"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"2.5em"}},[a("span",{style:{top:"-4.66em"}},[a("span",{class:"pstrut",style:{height:"3em"}}),a("span",{class:"mord"},[a("span",{class:"mord"}),a("span",{class:"mord"},"0"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∼"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mord"},"63")])]),a("span",{style:{top:"-3.16em"}},[a("span",{class:"pstrut",style:{height:"3em"}}),a("span",{class:"mord"},[a("span",{class:"mord"}),a("span",{class:"mord"},"64"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"∗"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"32"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∼"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mord"},"64"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"∗"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"33"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"1")])]),a("span",{style:{top:"-1.66em"}},[a("span",{class:"pstrut",style:{height:"3em"}}),a("span",{class:"mord"},[a("span",{class:"mord"}),a("span",{class:"mord"},"64"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"∗"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mopen"},"("),a("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"1"),a("span",{class:"mclose"},")"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∼"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mord"},"64"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"∗"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mord"},"1")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"2em"}},[a("span")])])])])])]),a("span",{class:"tag"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"2.5em"}},[a("span",{style:{top:"-4.5em"}},[a("span",{class:"pstrut",style:{height:"2.84em"}}),a("span",{class:"eqn-num"})]),a("span",{style:{top:"-3em"}},[a("span",{class:"pstrut",style:{height:"2.84em"}}),a("span",{class:"eqn-num"})]),a("span",{style:{top:"-1.5em"}},[a("span",{class:"pstrut",style:{height:"2.84em"}}),a("span",{class:"eqn-num"})])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"2em"}},[a("span")])])])])])])])]),a("p",null,"都被映射到Cache第一块中；"),a("p",null,"同理，第2块，第34块，以及第（N*32+2）块都被映射到Cache第二块中；可以依次类推其他内存块。")]),a("li",null,[a("p",null,"原理 - 目录表：两部分组成："),a("ul",null,[a("li",null,[a("p",null,"区号")]),a("li",null,[a("p",null,"有效位")])])]),a("li",null,[a("p",null,"原理 - 查找："),a("p",null,"其查找过程如下图所示。"),a("p",null,"首先，内存地址被分成三部分：区号A、块号B和块内地址C。根据区号A在目录表中找到完全相等的区号，"),a("ul",null,[a("li",null,[l("并且在有效位有效的情况下，说明该数据"),a("strong",null,"Cache命中"),l("，然后通过内存地址的块号B获得在Cache中的块地址，加上块内地址C，最终找到数据。")]),a("li",null,[l("如果在目录表中找不到相等的区号，或者有效位无效的情况下，则说明该内容"),a("strong",null,"Cache Miss"),l("，需要到内存中读取。")])]),a("p",null,"图2-6　直接相联Cache查找过程"),a("figure",null,[a("img",{src:i,alt:"img",tabindex:"0",loading:"lazy"}),a("figcaption",null,"img")]),a("p",null,"可以看出，直接关联是一种很“死”的映射方法，当映射到同一个Cache块的多个内存块同时需要缓存在Cache中时，只有一个内存块能够缓存，其他块需要被“淘汰”掉。")]),a("li",null,[a("p",null,"优点：其实现方式最为简单，匹配速度也最快。")]),a("li",null,[a("p",null,"缺点：但直接关联型命中率是最低的")])],-1),o=s('<h3 id="组关联型cache-n-ways-associative-cache" tabindex="-1"><a class="header-anchor" href="#组关联型cache-n-ways-associative-cache"><span>组关联型Cache（N-ways associative cache）</span></a></h3><ul><li><p>特点</p><p>组关联型Cache是目前Cache中用的比较广泛的一种方式，是<strong>前两种Cache的折中形式</strong>。</p><p>在这种方式下，内存被分为很多组，一个组的大小为多个Cache line的大小，一个组映射到对应的多个连续的Cache line，也就是一个Cache组，并且该组内的任意一块可以映射到对应Cache组的任意一个。可以看出：</p><ul><li>在组外，其采用直接关联型Cache的映射方式</li><li>在组内，其采用全关联型Cache的映射方式。</li></ul><p>假设有一个4路组关联型Cache，其大小为1M，一个Cache line的大小为64B，那么总共有16K个Cache line，但是在4路组关联的情况下，我们并不是简简单单拥有16K个Cache line，而是拥有了4K个组，每个组有4个Cache line。一个内存单元可以缓存到它所对应的组中的任意一个Cache line中去。</p></li><li><p>原理 - 目录表：三部分组成：</p><ul><li>“区号+块号”</li><li>Cache块号</li><li>有效位</li></ul></li><li><p>原理 - 查找</p><p>图2-7以4路组关联型Cache为例介绍其在Cache中的查找过程。当收到一个内存地址时，该地址被分成四部分：区号A、组号B、块号C和块内地址D。首先，根据组号B按地址查找到一组目录表项，在4路组关联中，则有四个表项，每个表项都有可能存放该内存块；然后，根据区号A和块号C在该组表项中进行关联查找（即并行查找，为了提高效率），如果匹配且有效位有效，则表明该数据块缓存在Cache中，得到Cache块号，加上块内地址D，可以得到该内存地址在Cache中映射的地址，得到数据；如果没有找到匹配项或者有效位无效，则表示该内存块不在Cache中，需要处理器到内存中读取。</p><p>图2-7　4路组关联型Cache查找过程</p><figure><img src="'+p+'" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>实际上，直接关联型Cache和全关联型Cache只是组关联型Cache的特殊情况。</p><ul><li>当组内Cache Line数目为1时，即为直接关联型Cache。</li><li>而当组内Cache Line数目和Cache大小相等时，即整个Cache只有一个组，这成为全关联型Cache。</li></ul></li></ul>',2),u=[m,h,o];function d(g,C){return t(),n("div",null,u)}const B=e(r,[["render",d],["__file","03. Cache地址映射和变换.html.vue"]]),v=JSON.parse('{"path":"/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/02.%20Theory/Computer/03.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%20-%20%E4%B8%93%E9%A2%98%E6%88%96%E5%AD%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AD%97%E5%85%B8%E7%89%88/%E4%B8%8B%E5%B1%82%E7%9B%B8%E5%85%B3/Network/%E3%80%8ANFV%E7%9A%84%E5%9F%BA%E7%9F%B3_%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BADPDK%E3%80%8B/02.%20Cache%E5%92%8C%E5%86%85%E5%AD%98/03.%20Cache%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84%E5%92%8C%E5%8F%98%E6%8D%A2.html","title":"Cache地址映射和变换","lang":"zh-CN","frontmatter":{"description":"Cache地址映射和变换 这章的重点是：Cache和内存的 数据交换，关系Cache和内存的读写。 底层细节和术语 为了进行Cache和内存的数据交换，这里介绍一点底层细节和术语： 分块机制 这里的分“块”指的“块”也叫“CacheLine”，Cache和内存以块为单位进行数据交换，块的大小通常以在内存的一个存储周期中能够访问到的数据长度为限。 注 (...","head":[["meta",{"property":"og:url","content":"http://192.168.0.101:8080/MdNote_Public/01.%20%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E4%BA%A7/Develop/02.%20Theory/Computer/03.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%20-%20%E4%B8%93%E9%A2%98%E6%88%96%E5%AD%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AD%97%E5%85%B8%E7%89%88/%E4%B8%8B%E5%B1%82%E7%9B%B8%E5%85%B3/Network/%E3%80%8ANFV%E7%9A%84%E5%9F%BA%E7%9F%B3_%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BADPDK%E3%80%8B/02.%20Cache%E5%92%8C%E5%86%85%E5%AD%98/03.%20Cache%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84%E5%92%8C%E5%8F%98%E6%8D%A2.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"Cache地址映射和变换"}],["meta",{"property":"og:description","content":"Cache地址映射和变换 这章的重点是：Cache和内存的 数据交换，关系Cache和内存的读写。 底层细节和术语 为了进行Cache和内存的数据交换，这里介绍一点底层细节和术语： 分块机制 这里的分“块”指的“块”也叫“CacheLine”，Cache和内存以块为单位进行数据交换，块的大小通常以在内存的一个存储周期中能够访问到的数据长度为限。 注 (..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"LincZero"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Cache地址映射和变换\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"Cache地址映射和变换","slug":"cache地址映射和变换","link":"#cache地址映射和变换","children":[{"level":2,"title":"底层细节和术语","slug":"底层细节和术语","link":"#底层细节和术语","children":[{"level":3,"title":"分块机制","slug":"分块机制","link":"#分块机制","children":[]},{"level":3,"title":"映射算法","slug":"映射算法","link":"#映射算法","children":[]}]},{"level":2,"title":"三类Cache (粗)","slug":"三类cache-粗","link":"#三类cache-粗","children":[{"level":3,"title":"提前总结、比较","slug":"提前总结、比较","link":"#提前总结、比较","children":[]},{"level":3,"title":"全关联型Cache（full associative cache）","slug":"全关联型cache-full-associative-cache","link":"#全关联型cache-full-associative-cache","children":[]},{"level":3,"title":"直接关联型Cache（direct mapped cache）","slug":"直接关联型cache-direct-mapped-cache","link":"#直接关联型cache-direct-mapped-cache","children":[]},{"level":3,"title":"组关联型Cache（N-ways associative cache）","slug":"组关联型cache-n-ways-associative-cache","link":"#组关联型cache-n-ways-associative-cache","children":[]}]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":8.02,"words":2405},"filePathRelative":"MdNote_Public/01. 设计开发与数据生产/Develop/02. Theory/Computer/03. 计算机系统 - 专题或子系统的字典版/下层相关/Network/《NFV的基石_深入浅出DPDK》/02. Cache和内存/03. Cache地址映射和变换.md","excerpt":"\\n<p>这章的重点是：<strong>Cache和内存的 数据交换</strong>，关系Cache和内存的读写。</p>\\n<h2>底层细节和术语</h2>\\n<p>为了进行Cache和内存的数据交换，这里介绍一点底层细节和术语：</p>\\n<h3>分块机制</h3>\\n<p>这里的分“块”指的“块”也叫“CacheLine”，Cache和内存以块为单位进行数据交换，块的大小通常以在内存的一个存储周期中能够访问到的数据长度为限。</p>\\n<div class=\\"hint-container note\\">\\n<p class=\\"hint-container-title\\">注</p>\\n<p>(GPT) 术语：<strong>Cache Line (缓存行)</strong></p>\\n<ul>\\n<li>概念：缓存行是内存中基本单位/<strong>最小的数据单位，它可以被加载到缓存中</strong>。</li>\\n<li>包含内容：一个缓存行通常包含：\\n<ul>\\n<li>实际的数据</li>\\n<li>一些元数据（例如有效位、脏位、共享状态等）</li>\\n</ul>\\n</li>\\n<li>大小：是最小数据单位。且其大小通常是固定的，并且因不同的处理器架构而异。常见的有：\\n<ul>\\n<li>32字节： 较早的ARM、1990年~2000年早期的x86和PowerPC</li>\\n<li>64字节： 较新的ARM和x86</li>\\n<li>128字节： 较新的Power ISA机器</li>\\n</ul>\\n</li>\\n<li><strong>机制 - 整个加载以利用局部性原理</strong>：每次从主内存读取数据时，不仅仅是请求的特定字节会被加载，而是整个缓存行都会被加载到缓存中。\\n这样做的目的是为了利用局部性原理（Locality Principle），即程序往往连续访问内存中的数据或在短时间内重复访问相同的数据。</li>\\n<li><strong>机制 - 缓存行对齐以确保高效加载</strong>：数据在内存中的位置需要与缓存行边界对齐</li>\\n</ul>\\n</div>","autoDesc":true}');export{B as comp,v as data};
