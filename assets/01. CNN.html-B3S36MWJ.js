import{_ as n,c as a,e as l,o as i}from"./app-DEUP2Tjk.js";const t="/assets/image-20221103121731785-BToYvnNl.png",s="/assets/image-20221103122609639-8HSwFhhK.png",p="/assets/image-20221103123240900-rQGpljeq.png",o="/assets/image-20221103134557737-B2jjiBcp.png",r="/assets/image-20221103153319895-Dd9ONhjT.png",c="/assets/image-20221103153456455-BJMLF9fH.png",h="/assets/image-20221103141809443-DPXpi_e1.png",d="/assets/image-20221103150519784-DKSnd_i1.png",g="/assets/image-20221103150903926-Dr_E_7-K.png",m="/assets/image-20221103153823066-DaHxcJWQ.png",u={};function N(v,e){return i(),a("div",null,e[0]||(e[0]=[l('<h1 id="李宏毅机器学习深度学习" tabindex="-1"><a class="header-anchor" href="#李宏毅机器学习深度学习"><span>李宏毅机器学习深度学习</span></a></h1><h1 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h1><h1 id="cnn-convolutional-neural-network" tabindex="-1"><a class="header-anchor" href="#cnn-convolutional-neural-network"><span>CNN（Convolutional Neural Network）</span></a></h1><p>对应视频：P31 对应pdf：09_CNN.pdf</p><h2 id="图片分类" tabindex="-1"><a class="header-anchor" href="#图片分类"><span>图片分类</span></a></h2><h3 id="参数量爆炸" tabindex="-1"><a class="header-anchor" href="#参数量爆炸"><span>参数量爆炸</span></a></h3><p>是怎麼把一张影像当做一个模型的输入 对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量） 如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的矩阵就是 Tensor</p><p><img src="'+t+'" alt="image-20221103121731785" loading="lazy"></p><p>一些翻译：</p><ul><li>Tensor，[数] 张量</li><li>channels，通道</li><li>pattern，模式、图案</li><li>Receptive Field，感受野、接受野、卷积野</li></ul><p>如果全连接（Fully Connected）</p><blockquote><p>虽然随著参数的增加,我们可以增加模型的弹性,我们可以增加它的能力,但是我们也增加了 Overfitting 的风 险,有关什麼叫模型的弹性,到底 Overfitting 怎麼產生的,下週吴培元老师https://speech.ee.ntu.edu.tw/~hyle e/ml/ml2021-course-data/W14_PAC-introduction.pdf会从数学上,给大家非常清楚的证明,那我们这边就讲 概念上,如果模型的弹性越大,就越容易 Overfitting</p></blockquote><h3 id="解决方法" tabindex="-1"><a class="header-anchor" href="#解决方法"><span>解决方法</span></a></h3><p>两种简化的方法</p><h4 id="感受野" tabindex="-1"><a class="header-anchor" href="#感受野"><span>感受野</span></a></h4><p>Pattern检测、感受野</p><blockquote><p>是判断说现在有没有某种 Pattern 出现时，我们并不需要每 一个 Neuron都去看一张完整的图片</p><p>所以这些 Neuron 也许根本就不需要,把整张图片当作输入,它们只需要把图片的一小部分当作输入,就足以让 它们侦测某些特别关键的 Pattern有没有出现了</p><p>我们会设定一个区域叫做 <strong>Receptive Field（感受野、接受野、卷积野）</strong>,每一个 Neuron 都只关心自己的 Receptive Field 裡面发生的事情就好了</p></blockquote><p>一些想法：</p><ul><li>我可不可以 Receptive Field 有大有小呢？可以</li><li>我可不可以 Receptive Field,只考虑某些 Channel 呢？可以</li><li>可不可以是长方形？可以！</li><li>Receptive Field 一定要相连吗？理论上可以，但是这种特征应该很少见，二维码区域识别应该算</li></ul><p><img src="'+s+'" alt="image-20221103122609639" loading="lazy"></p><p>一些概念</p><ul><li>Kernel Size（核尺寸） <ul><li>我们在描述一个 Receptive Field 的时候,只要讲它的高跟宽就好了。 就不用讲它的深度，反正深度一定是考虑全部的 Channel。 而这个高跟宽合起来叫做 Kernel Size</li><li>一般3x3，也有5x5，7x7</li></ul></li><li>Stride（步幅） <ul><li>Stride 是一个你自己决定的 Hyperparameter,但这个 Stride 你往往 不会设太大,往往设 1 或 2 就可以了</li><li>超出的就不要，或者做padding</li></ul></li><li>Padding（填充，补值）</li></ul><h4 id="共享参数" tabindex="-1"><a class="header-anchor" href="#共享参数"><span>共享参数</span></a></h4><p>同样的 Pattern，它可能会出现在图片的不同区域裡面</p><p>我们真的需要每一个守备范围,都去放一个侦测鸟嘴的 Neuron 吗？不需要！</p><p>放在影像处理上的话,我们能不能够让,不同 Receptive Field 的 Neuron共享参数,也就是做 Parameter Sharing权值共享</p><p><img src="'+p+'" alt="image-20221103123240900" loading="lazy"></p><p>位置不同但可以使用相同的权重！</p><p>具体上，怎么去共享参数？</p><p>你完全可以自己决定，而这个是你可以自己决定的事情，但是接下来还是要告诉大家，常见的在影像辨识上面的共享的方法,是怎麼设定的</p><p>实每一个 Receptive Field都只有一组参数而已，那这些参数有一个名字，叫做 <strong>Filter（卷积核、过滤器、滤波器</strong>）</p><p><img src="'+o+'" alt="image-20221103134557737" loading="lazy"></p><h4 id="pooling-池化层" tabindex="-1"><a class="header-anchor" href="#pooling-池化层"><span>Pooling 池化层</span></a></h4><p>把一张大的图片缩小，这是一隻鸟，这张小的图片看起来还是一隻鸟</p><p><img src="'+r+'" alt="image-20221103153319895" loading="lazy"></p><p>Pooling 这个东西啊,它本身没有参数,所以它不是一个 Layer,它裡面没有 Weight,它没有要 Learn 的东西</p><p>所以 有人会告诉你说 Pooling 比较像是一个 Activation Function,比较像是 Sigmoid ， ReLU 那些,因為它裡面是 没有要 Learn 的东西的,它就是一个 Operator,它的行為都是固定好的,没有要根据 Data 学任何东西</p><p>Pooling 其实也有很多不同的版本,我们这边讲的是 Max Pooling</p><blockquote><h5 id="maxpooling" tabindex="-1"><a class="header-anchor" href="#maxpooling"><span>MaxPooling</span></a></h5></blockquote><p><img src="'+c+'" alt="image-20221103153456455" loading="lazy"></p><p>在这个例子 裡面就是 2×2 个一组,每一组裡面选一个代表,在 Max Pooling 裡面,我们选的代表就是最大的那一个</p><p><strong>一般在实际上，Convolution和Pooling会交替使用</strong></p><p>Pooling会带来一点图片损耗，最近运算能力越来越强，有的网络的设计甚至不用Pooling，Full Convolution</p><h3 id="整理总结" tabindex="-1"><a class="header-anchor" href="#整理总结"><span>整理总结</span></a></h3><p><img src="'+h+'" alt="image-20221103141809443" loading="lazy"></p><p>我们加了 <strong>感受野</strong> 和 <strong>参数共享</strong> 来限制全连接，变成卷积层 CNN。</p><p>CNN 的弹性小了很多，Bias 比较大 可能有小伙伴会说 Model Bias 比较大 不是一件坏事吗？ Model Bias 大，不一定是坏事</p><ul><li>因為当 Model Bias 小，Model 的 Flexibility 很高的时候，它比较容易 Overfitting。</li><li>虽然Fully Connected Layer可以做各式各样的事情，它可以有各式各样的变化，但是它可能没有办法在任何特定的任务上做好</li><li>Convolutional Layer它是专门為影像设计的。刚才讲的 Receptive Field 参数共享，这些观察 都是為影像设计的，所以它在影像上仍然可以做得好。 虽然它的 Model Bias 很大，但这个在影像上不是问题。但是如果它用在影像之外的任务，你就要仔细想想那些任务有没有我们刚才讲的影像用的特性</li></ul><h2 id="卷积层" tabindex="-1"><a class="header-anchor" href="#卷积层"><span>卷积层</span></a></h2><p>Convolutional 的 Layer 就是裡面有很多的 Filter</p><p>一个 Convolutional 的 Layer 裡面就是有一排的 Filter，一个 Filter 的作用就是要去图片裡面某一个 Pattern</p><h3 id="卷积操作、特征图谱" tabindex="-1"><a class="header-anchor" href="#卷积操作、特征图谱"><span>卷积操作、特征图谱</span></a></h3><p>把 Filter 裡面所有的值,跟左上角这个范围内的 9 个值做相乘,也就是把这个 Filter 裡面的 9 个值,跟这个范围裡 面的 9 个值呢,做 Inner Product,做完是 3</p><p>注意！在此处卷集运算中，老师讲的内积，不要理解为线性代数中矩阵的乘法，而是filter跟图片对应位置的 数值直接相乘，所有的都乘完以后再相加</p><p><img src="'+d+'" alt="image-20221103150519784" loading="lazy"></p><p>假设有64个过滤器，那么我们就得到 64 群的数字了。 这一群数字啊，它又有一个名字，它叫做 <strong>Feature Map（特征图谱）</strong></p><p>如果我们的 Filter 的大小一直设 3 × 3,会不会让我们的 Network,没有办法看比较大范围的 Pattern 呢？不会</p><p>例如当我们看这 3 × 3 的范围的Feature Map时候，其实是考虑了一个 5 × 5 的范围</p><p><img src="'+g+'" alt="image-20221103150903926" loading="lazy"></p><p>所以 Network 够深,你不用怕你侦测不到比较 大的 Pattern,它还是可以侦测到比较大的 Pattern</p><h3 id="整个cnn" tabindex="-1"><a class="header-anchor" href="#整个cnn"><span>整个CNN</span></a></h3><p><img src="'+m+'" alt="image-20221103153823066" loading="lazy"></p><h2 id="怎么使用cnn下围棋" tabindex="-1"><a class="header-anchor" href="#怎么使用cnn下围棋"><span>怎么使用CNN下围棋？</span></a></h2><p>可以将棋盘表示成一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>19</mn><mo>×</mo><mn>19</mn></mrow><annotation encoding="application/x-tex">19\\times 19</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">19</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">19</span></span></span></span>的二维向量作为输入，然后可以变成一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>19</mn><mo>×</mo><mn>19</mn></mrow><annotation encoding="application/x-tex">19\\times 19</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">19</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">19</span></span></span></span>的多分类问题</p><p>CNN会比Fully-connected的效果更好。AlphaGo的原始论文里说，每一个Pixel，它是用 48 个 Channel 来 描述</p><p>有一点与图像识别不同：</p><blockquote><p>在做影像的时候我们说我们都会做 Pooling，一张影像做 Subsampling 以后, 并不会影响我们对影像中物件的判读</p><p>但是棋盘是这个样子吗？你可以把棋盘上的奇数行跟偶数列拿掉，还是同一个棋局吗？ 下围棋这麼精细的任务,你随便拿掉一个 Column 拿掉一个 Row，整个棋整个局势就不一样了</p></blockquote><h2 id="局限性" tabindex="-1"><a class="header-anchor" href="#局限性"><span>局限性</span></a></h2><p>CNN，没有办法处理影像放大缩小，或者是旋转的问题</p><p>那就是為什麼在做影像辨识的时候，往往都要做 Data Augmentation</p>',70)]))}const C=n(u,[["render",N],["__file","01. CNN.html.vue"]]),k=JSON.parse('{"path":"/MdNote_Public/01.%20DesignAndDevelop/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/02.%20%E6%9D%8E%E5%AE%8F%E6%AF%85%202020%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03.%20CNN/01.%20CNN.html","title":"李宏毅机器学习深度学习","lang":"zh-CN","frontmatter":{"description":"李宏毅机器学习深度学习 目录 CNN（Convolutional Neural Network） 对应视频：P31 对应pdf：09_CNN.pdf 图片分类 参数量爆炸 是怎麼把一张影像当做一个模型的输入 对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量） 如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的...","head":[["meta",{"property":"og:url","content":"https://LincZero.github.io/MdNote_Public/01.%20DesignAndDevelop/Develop/04.%20Project/Type/Artificial_Intelligence/%E7%BA%BF%E6%80%A7%E5%9E%8B/02.%20%E6%9D%8E%E5%AE%8F%E6%AF%85%202020%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03.%20CNN/01.%20CNN.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"李宏毅机器学习深度学习"}],["meta",{"property":"og:description","content":"李宏毅机器学习深度学习 目录 CNN（Convolutional Neural Network） 对应视频：P31 对应pdf：09_CNN.pdf 图片分类 参数量爆炸 是怎麼把一张影像当做一个模型的输入 对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量） 如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"李宏毅机器学习深度学习\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"李宏毅机器学习深度学习","slug":"李宏毅机器学习深度学习","link":"#李宏毅机器学习深度学习","children":[]},{"level":1,"title":"目录","slug":"目录","link":"#目录","children":[]},{"level":1,"title":"CNN（Convolutional Neural Network）","slug":"cnn-convolutional-neural-network","link":"#cnn-convolutional-neural-network","children":[{"level":2,"title":"图片分类","slug":"图片分类","link":"#图片分类","children":[{"level":3,"title":"参数量爆炸","slug":"参数量爆炸","link":"#参数量爆炸","children":[]},{"level":3,"title":"解决方法","slug":"解决方法","link":"#解决方法","children":[{"level":4,"title":"感受野","slug":"感受野","link":"#感受野","children":[]},{"level":4,"title":"共享参数","slug":"共享参数","link":"#共享参数","children":[]},{"level":4,"title":"Pooling 池化层","slug":"pooling-池化层","link":"#pooling-池化层","children":[]}]},{"level":3,"title":"整理总结","slug":"整理总结","link":"#整理总结","children":[]}]},{"level":2,"title":"卷积层","slug":"卷积层","link":"#卷积层","children":[{"level":3,"title":"卷积操作、特征图谱","slug":"卷积操作、特征图谱","link":"#卷积操作、特征图谱","children":[]},{"level":3,"title":"整个CNN","slug":"整个cnn","link":"#整个cnn","children":[]}]},{"level":2,"title":"怎么使用CNN下围棋？","slug":"怎么使用cnn下围棋","link":"#怎么使用cnn下围棋","children":[]},{"level":2,"title":"局限性","slug":"局限性","link":"#局限性","children":[]}]}],"git":{},"readingTime":{"minutes":6.39,"words":1918},"filePathRelative":"MdNote_Public/01. DesignAndDevelop/Develop/04. Project/Type/Artificial_Intelligence/线性型/02. 李宏毅 2020机器学习深度学习/03. CNN/01. CNN.md","excerpt":"\\n<h1>目录</h1>\\n<h1>CNN（Convolutional Neural Network）</h1>\\n<p>对应视频：P31\\n对应pdf：09_CNN.pdf</p>\\n<h2>图片分类</h2>\\n<h3>参数量爆炸</h3>\\n<p>是怎麼把一张影像当做一个模型的输入\\n对於一个 Machine 来说,一张图片其实是一个三维的 Tensor（张量）\\n如果不知道 Tensor 是什麼的话,你就想成它是维度大於 2 的矩阵就是 Tensor</p>\\n<p></p>\\n<p>一些翻译：</p>\\n<ul>\\n<li>Tensor，[数] 张量</li>\\n<li>channels，通道</li>\\n<li>pattern，模式、图案</li>\\n<li>Receptive Field，感受野、接受野、卷积野</li>\\n</ul>","autoDesc":true,"bioChainData":{"outlink":[],"backlink":[],"localMap":{"nodes":[{"id":"MdNote_Public/01. DesignAndDevelop/Develop/04. Project/Type/Artificial_Intelligence/线性型/02. 李宏毅 2020机器学习深度学习/03. CNN/01. CNN.md","value":{"title":"01. CNN","path":"MdNote_Public/01. DesignAndDevelop/Develop/04. Project/Type/Artificial_Intelligence/线性型/02. 李宏毅 2020机器学习深度学习/03. CNN/01. CNN.md","outlink":[],"backlink":[]}}],"links":[]}}}');export{C as comp,k as data};
