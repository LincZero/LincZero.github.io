import{_ as p,c as l,a,b as e,d as n,e as i,o,r}from"./app-m8pBmpZD.js";const c="/assets/延迟队列-bNEixmDx.png",d="/assets/普通命令模式-D1ZW4wTj.jpg",u="/assets/管道模式-CDuhx3Zm.jpg",k="/assets/redis官方解释回滚-BnOg9eBh.png",m="/assets/分布式锁-57cW8m6K.jpg",v={},b={href:"https://redis.io/topics/transactions",target:"_blank",rel:"noopener noreferrer"};function h(g,s){const t=r("ExternalLinkIcon");return o(),l("div",null,[s[3]||(s[3]=a('<h1 id="redis-实战-未" tabindex="-1"><a class="header-anchor" href="#redis-实战-未"><span>Redis 实战 (未)</span></a></h1><h2 id="redis-实战" tabindex="-1"><a class="header-anchor" href="#redis-实战"><span>Redis 实战</span></a></h2><h3 id="延迟队列" tabindex="-1"><a class="header-anchor" href="#延迟队列"><span>延迟队列</span></a></h3><p>什么是延迟队列？</p><blockquote><p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：</p><ol><li>在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；</li><li>打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；</li><li>点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；</li></ol></blockquote><p>如何实现延迟队列？</p><blockquote><p>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。</p><p>使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。</p><p><img src="'+c+`" alt="img" loading="lazy"></p></blockquote><h3 id="redis-大-key" tabindex="-1"><a class="header-anchor" href="#redis-大-key"><span>Redis &quot;大 key&quot;</span></a></h3><h4 id="大-key-的含义" tabindex="-1"><a class="header-anchor" href="#大-key-的含义"><span>大 key 的含义</span></a></h4><p>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p><p>一般而言，下面这两种情况被称为大 key：</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 类型的元素的个数超过 5000个；</li></ul><h4 id="大-key-会造成什么问题" tabindex="-1"><a class="header-anchor" href="#大-key-会造成什么问题"><span>大 key 会造成什么问题</span></a></h4><p>大 key 会带来以下四种影响：</p><ul><li><strong>客户端超时阻塞</strong>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li><li><strong>引发网络阻塞</strong>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li><strong>阻塞工作线程</strong>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li><li><strong>内存分布不均</strong>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li></ul><h4 id="大-key-的寻找" tabindex="-1"><a class="header-anchor" href="#大-key-的寻找"><span>大 key 的寻找</span></a></h4><h5 id="redis-cli-bigkeys-查找大key" tabindex="-1"><a class="header-anchor" href="#redis-cli-bigkeys-查找大key"><span>redis-cli --bigkeys 查找大key</span></a></h5><p>可以通过 redis-cli --bigkeys 命令查找大 key：</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>redis-cli <span class="token parameter variable">-h</span> <span class="token number">127.0</span>.0.1 <span class="token parameter variable">-p6379</span> <span class="token parameter variable">-a</span> <span class="token string">&quot;password&quot;</span> -- bigkeys
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>使用的时候注意事项：</p><ul><li>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；</li><li>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li></ul><p>该方式的不足之处：</p><ul><li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；</li><li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</li></ul><h5 id="使用-scan-命令查找" tabindex="-1"><a class="header-anchor" href="#使用-scan-命令查找"><span>使用 SCAN 命令查找</span></a></h5><p>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。</p><p>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。</p><p>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p><ul><li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：<code>LLEN</code> 命令；Hash 类型：<code>HLEN</code> 命令；Set 类型：<code>SCARD</code> 命令；Sorted Set 类型：<code>ZCARD</code> 命令；</li><li>如果不能提前知道写入集合的元素大小，可以使用 <code>MEMORY USAGE</code> 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</li></ul><h5 id="使用-rdbtools-工具查找" tabindex="-1"><a class="header-anchor" href="#使用-rdbtools-工具查找"><span>使用 RdbTools 工具查找</span></a></h5><p>使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。</p><p>比如，下面这条命令，将大于 10 kb 的 key 输出到一个表格文件。</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>rdb dump.rdb <span class="token parameter variable">-c</span> memory <span class="token parameter variable">--bytes</span> <span class="token number">10240</span> <span class="token parameter variable">-f</span> redis.csv
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="大-key-的删除" tabindex="-1"><a class="header-anchor" href="#大-key-的删除"><span>大 key 的删除</span></a></h4><p>删除操作的本质是要释放键值对占用的内存空间，不要小瞧内存的释放过程。</p><p>释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。</p><p>所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。</p><p>因此，删除大 key 这一个动作，我们要小心。具体要怎么做呢？这里给出两种方法：</p><ul><li>分批次删除</li><li>异步删除（Redis 4.0版本以上）</li></ul><h5 id="分批次删除" tabindex="-1"><a class="header-anchor" href="#分批次删除"><span>分批次删除</span></a></h5><p>对于<strong>删除大 Hash</strong>，使用 <code>hscan</code> 命令，每次获取 100 个字段，再用 <code>hdel</code> 命令，每次删除 1 个字段。</p><p>Python代码：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_hash</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;redis-host1&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
    large_hash_key <span class="token operator">=</span><span class="token string">&quot;xxx&quot;</span> <span class="token comment">#要删除的大hash键名</span>
    cursor <span class="token operator">=</span> <span class="token string">&#39;0&#39;</span>
    <span class="token keyword">while</span> cursor <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用 hscan 命令，每次获取 100 个字段</span>
        cursor<span class="token punctuation">,</span> data <span class="token operator">=</span> r<span class="token punctuation">.</span>hscan<span class="token punctuation">(</span>large_hash_key<span class="token punctuation">,</span> cursor<span class="token operator">=</span>cursor<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># 再用 hdel 命令，每次删除1个字段</span>
                r<span class="token punctuation">.</span>hdel<span class="token punctuation">(</span>large_hash_key<span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于<strong>删除大 List</strong>，通过 <code>ltrim</code> 命令，每次删除少量元素。</p><p>Python代码：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_list</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;redis-host1&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
  large_list_key <span class="token operator">=</span> <span class="token string">&#39;xxx&#39;</span>  <span class="token comment">#要删除的大list的键名</span>
  <span class="token keyword">while</span> r<span class="token punctuation">.</span>llen<span class="token punctuation">(</span>large_list_key<span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">:</span>
      <span class="token comment">#每次只删除最右100个元素</span>
      r<span class="token punctuation">.</span>ltrim<span class="token punctuation">(</span>large_list_key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">101</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于<strong>删除大 Set</strong>，使用 <code>sscan</code> 命令，每次扫描集合中 100 个元素，再用 <code>srem</code> 命令每次删除一个键。</p><p>Python代码：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_set</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;redis-host1&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
  large_set_key <span class="token operator">=</span> <span class="token string">&#39;xxx&#39;</span>   <span class="token comment"># 要删除的大set的键名</span>
  cursor <span class="token operator">=</span> <span class="token string">&#39;0&#39;</span>
  <span class="token keyword">while</span> cursor <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token comment"># 使用 sscan 命令，每次扫描集合中 100 个元素</span>
    cursor<span class="token punctuation">,</span> data <span class="token operator">=</span> r<span class="token punctuation">.</span>sscan<span class="token punctuation">(</span>large_set_key<span class="token punctuation">,</span> cursor<span class="token operator">=</span>cursor<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">:</span>
      <span class="token comment"># 再用 srem 命令每次删除一个键</span>
      r<span class="token punctuation">.</span>srem<span class="token punctuation">(</span>large_size_key<span class="token punctuation">,</span> item<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于<strong>删除大 ZSet</strong>，使用 <code>zremrangebyrank</code> 命令，每次删除 top 100个元素。</p><p>Python代码：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_sortedset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;large_sortedset_key&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
  large_sortedset_key<span class="token operator">=</span><span class="token string">&#39;xxx&#39;</span>
  <span class="token keyword">while</span> r<span class="token punctuation">.</span>zcard<span class="token punctuation">(</span>large_sortedset_key<span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token comment"># 使用 zremrangebyrank 命令，每次删除 top 100个元素</span>
    r<span class="token punctuation">.</span>zremrangebyrank<span class="token punctuation">(</span>large_sortedset_key<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">99</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="异步删除" tabindex="-1"><a class="header-anchor" href="#异步删除"><span>异步删除</span></a></h5><p>从 Redis 4.0 版本开始，可以采用<strong>异步删除</strong>法，<strong>用 unlink 命令代替 del 来删除</strong>。</p><p>这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。</p><p>除了主动调用 unlink 命令实现异步删除之外，我们还可以通过配置参数，达到某些条件的时候自动进行异步删除。</p><p>主要有 4 种场景，默认都是关闭的。它们代表的含义如下：</p><ul><li><em>lazyfree-lazy-eviction</em>： 表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除</li><li><em>lazyfree-lazy-expire</em>： 表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除</li><li><em>lazyfree-lazy-server-del</em>： 有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除</li><li><em>slave-lazy-flush</em>： 针对 slave (从节点) 进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除</li></ul><p>建议开启其中的 lazyfree-lazy-eviction、lazyfree-lazy-expire、lazyfree-lazy-server-del 等配置，这样就可以有效的提高主线程的执行效率。</p><h3 id="redis-管道有什么用" tabindex="-1"><a class="header-anchor" href="#redis-管道有什么用"><span>Redis 管道有什么用？</span></a></h3><p>管道技术（Pipeline）是客户端提供的一种批处理技术，用于<em>一次处理多个 Redis 命令</em>，从而提高整个交互的性能。</p><p>普通命令模式，如下图所示：</p><p><img src="`+d+'" alt="img" loading="lazy"></p><p>管道模式，如下图所示：</p><p><img src="'+u+`" alt="img" loading="lazy"></p><ul><li>优点 <ul><li><strong>可以解决多个命令执行时的网络等待</strong>，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率</li></ul></li><li>缺点 <ul><li>但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞</li></ul></li></ul><p>要注意的是，管道技术<em>本质上是客户端提供的功能，而非 Redis 服务器端的功能</em></p><h3 id="redis-事务支持回滚吗" tabindex="-1"><a class="header-anchor" href="#redis-事务支持回滚吗"><span>Redis 事务支持回滚吗？</span></a></h3><h4 id="不支持-只支持放弃事务执行" tabindex="-1"><a class="header-anchor" href="#不支持-只支持放弃事务执行"><span>不支持，只支持放弃事务执行</span></a></h4><p>MySQL 在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态。</p><p><strong>Redis 中并没有提供回滚机制</strong>，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。</p><p>下面是 DISCARD 命令用法：</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code>#读取 count 的值<span class="token number">4</span>
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> GET count
<span class="token string">&quot;1&quot;</span>
#开启事务
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> MULTI 
OK
#发送事务的第一个操作，对count减<span class="token number">1</span>
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> DECR count
QUEUED
#执行DISCARD命令，主动放弃事务
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> DISCARD
OK
#再次读取a<span class="token operator">:</span>stock的值，值没有被修改
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> GET count
<span class="token string">&quot;1&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>事务执行过程中，如果命令入队时没报错，而事务提交后，实际执行时报错了，正确的命令依然可以正常执行，所以这可以看出 <strong>Redis 并不一定保证原子性</strong>（原子性：事务中的命令要不全部成功，要不全部失败）。</p><p>比如下面这个例子：</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code>#获取name原本的值
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> GET name
<span class="token string">&quot;xiaolin&quot;</span>
#开启事务
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> MULTI
OK
#设置新值
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> SET name xialincoding
QUEUED
#注意，这条命令是错误的
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">expire</span> <span class="token expression">过期时间正确来说是数字，并不是‘<span class="token number">10</span>s’字符串，但是还是入队成功了</span></span>
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> EXPIRE name <span class="token number">10</span>s
QUEUED
#提交事务，执行报错
#可以看到 set 执行成功，而 expire 执行错误。
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> EXEC
<span class="token number">1</span><span class="token punctuation">)</span> OK
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>error<span class="token punctuation">)</span> ERR value is not an integer or out of range
#可以看到，name 还是被设置为新值了
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> GET name
<span class="token string">&quot;xialincoding&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="为什么不支持事务回滚" tabindex="-1"><a class="header-anchor" href="#为什么不支持事务回滚"><span>为什么不支持事务回滚</span></a></h4>`,76)),e("p",null,[s[1]||(s[1]=n("Redis ")),e("a",b,[s[0]||(s[0]=n("官方文档")),i(t)]),s[2]||(s[2]=n(" 的解释如下："))]),s[4]||(s[4]=a('<p><img src="'+k+'" alt="img" loading="lazy"></p><p>大概的意思是，作者不支持事务回滚的原因有以下两个：</p><ul><li>他认为 Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能；</li><li>不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。</li></ul><p>这里不支持事务回滚，指的是不支持事务运行时错误的事务回滚。</p><h3 id="用-redis-实现分布式锁" tabindex="-1"><a class="header-anchor" href="#用-redis-实现分布式锁"><span>用 Redis 实现分布式锁</span></a></h3><h4 id="分布式锁概念" tabindex="-1"><a class="header-anchor" href="#分布式锁概念"><span>分布式锁概念</span></a></h4><p>分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。如下图所示：</p><p><img src="'+m+`" alt="img" loading="lazy"></p><h4 id="如何用-redis-实现分布式锁-用-set-nx-参数" tabindex="-1"><a class="header-anchor" href="#如何用-redis-实现分布式锁-用-set-nx-参数"><span>如何用 Redis 实现分布式锁？(用 SET NX 参数)</span></a></h4><p>Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。</p><p>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p><ul><li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li><li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li></ul><p>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p><ul><li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li><li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；</li><li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；</li></ul><p>满足这三个条件的分布式命令如下：</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code>SET lock_key unique_value NX PX <span class="token number">10000</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li>lock_key 就是 key 键；</li><li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；</li><li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；</li><li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。</li></ul><p>而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。</p><p>可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token comment">// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span>
<span class="token keyword">if</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">,</span>KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> ARGV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> then
    <span class="token keyword">return</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&quot;del&quot;</span><span class="token punctuation">,</span>KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">else</span>
    <span class="token keyword">return</span> <span class="token number">0</span>
end
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。</p><h4 id="基于-redis-的分布式锁优缺点" tabindex="-1"><a class="header-anchor" href="#基于-redis-的分布式锁优缺点"><span>基于 Redis 的分布式锁优缺点</span></a></h4><p><strong>优点</strong>：</p><ol><li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。</li><li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。</li><li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</li></ol><p><strong>缺点</strong>：</p><ul><li><p>超时时间不好设置。</p><p>如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。</p><ul><li><strong>那么如何合理设置超时时间呢？</strong> 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</li></ul></li><li><p><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</p></li></ul><h4 id="如何解决集群情况下分布式锁的可靠性" tabindex="-1"><a class="header-anchor" href="#如何解决集群情况下分布式锁的可靠性"><span>如何解决集群情况下分布式锁的可靠性</span></a></h4><p>为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。</p><p>它是基于<strong>多个 Redis 节点</strong>的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。</p><p>Redlock 算法的基本思路，<strong>是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败</strong>。</p><p>这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。</p><p>Redlock 算法加锁三个过程：</p><ul><li>第一步是，客户端获取当前时间（t1）。</li><li>第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作： <ul><li>加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。</li><li>如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。</li></ul></li><li>第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li></ul><p>可以看到，加锁成功要同时满足两个条件（<em>简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功</em>）：</p><ul><li>条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁；</li><li>条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。</li></ul><p>加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」。如果计算的结果已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。</p><p>加锁失败后，客户端向<strong>所有 Redis 节点发起释放锁的操作</strong>，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。</p>`,37))])}const E=p(v,[["render",h],["__file","09. 实战.html.vue"]]),R=JSON.parse('{"path":"/MdNote_Public/01.%20DesignAndDevelop/Develop/02.%20Theory/Computer/03.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%20-%20%E7%BA%BF%E6%80%A7%E5%AD%A6%E4%B9%A0%E7%89%88/%E3%80%8A%E5%B0%8F%E6%9E%97coding_%E5%9B%BE%E8%A7%A3%E7%B3%BB%E5%88%97%E3%80%8B/04.%20%E5%9B%BE%E8%A7%A3Redis/01.%20%E9%9D%A2%E8%AF%95%E7%AF%87/09.%20%E5%AE%9E%E6%88%98.html","title":"Redis 实战 (未)","lang":"zh-CN","frontmatter":{"description":"Redis 实战 (未) Redis 实战 延迟队列 什么是延迟队列？ 延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种： 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消； 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单； 点外卖的时候，如果商家在10分钟还没接单，就会...","head":[["meta",{"property":"og:url","content":"https://LincZero.github.io/MdNote_Public/01.%20DesignAndDevelop/Develop/02.%20Theory/Computer/03.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%20-%20%E7%BA%BF%E6%80%A7%E5%AD%A6%E4%B9%A0%E7%89%88/%E3%80%8A%E5%B0%8F%E6%9E%97coding_%E5%9B%BE%E8%A7%A3%E7%B3%BB%E5%88%97%E3%80%8B/04.%20%E5%9B%BE%E8%A7%A3Redis/01.%20%E9%9D%A2%E8%AF%95%E7%AF%87/09.%20%E5%AE%9E%E6%88%98.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"Redis 实战 (未)"}],["meta",{"property":"og:description","content":"Redis 实战 (未) Redis 实战 延迟队列 什么是延迟队列？ 延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种： 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消； 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单； 点外卖的时候，如果商家在10分钟还没接单，就会..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"LincZero"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Redis 实战 (未)\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"Redis 实战 (未)","slug":"redis-实战-未","link":"#redis-实战-未","children":[{"level":2,"title":"Redis 实战","slug":"redis-实战","link":"#redis-实战","children":[{"level":3,"title":"延迟队列","slug":"延迟队列","link":"#延迟队列","children":[]},{"level":3,"title":"Redis \\"大 key\\"","slug":"redis-大-key","link":"#redis-大-key","children":[{"level":4,"title":"大 key 的含义","slug":"大-key-的含义","link":"#大-key-的含义","children":[]},{"level":4,"title":"大 key 会造成什么问题","slug":"大-key-会造成什么问题","link":"#大-key-会造成什么问题","children":[]},{"level":4,"title":"大 key 的寻找","slug":"大-key-的寻找","link":"#大-key-的寻找","children":[{"level":5,"title":"redis-cli --bigkeys 查找大key","slug":"redis-cli-bigkeys-查找大key","link":"#redis-cli-bigkeys-查找大key","children":[]},{"level":5,"title":"使用 SCAN 命令查找","slug":"使用-scan-命令查找","link":"#使用-scan-命令查找","children":[]},{"level":5,"title":"使用 RdbTools 工具查找","slug":"使用-rdbtools-工具查找","link":"#使用-rdbtools-工具查找","children":[]}]},{"level":4,"title":"大 key 的删除","slug":"大-key-的删除","link":"#大-key-的删除","children":[{"level":5,"title":"分批次删除","slug":"分批次删除","link":"#分批次删除","children":[]},{"level":5,"title":"异步删除","slug":"异步删除","link":"#异步删除","children":[]}]}]},{"level":3,"title":"Redis 管道有什么用？","slug":"redis-管道有什么用","link":"#redis-管道有什么用","children":[]},{"level":3,"title":"Redis 事务支持回滚吗？","slug":"redis-事务支持回滚吗","link":"#redis-事务支持回滚吗","children":[{"level":4,"title":"不支持，只支持放弃事务执行","slug":"不支持-只支持放弃事务执行","link":"#不支持-只支持放弃事务执行","children":[]},{"level":4,"title":"为什么不支持事务回滚","slug":"为什么不支持事务回滚","link":"#为什么不支持事务回滚","children":[]}]},{"level":3,"title":"用 Redis 实现分布式锁","slug":"用-redis-实现分布式锁","link":"#用-redis-实现分布式锁","children":[{"level":4,"title":"分布式锁概念","slug":"分布式锁概念","link":"#分布式锁概念","children":[]},{"level":4,"title":"如何用 Redis 实现分布式锁？(用 SET NX 参数)","slug":"如何用-redis-实现分布式锁-用-set-nx-参数","link":"#如何用-redis-实现分布式锁-用-set-nx-参数","children":[]},{"level":4,"title":"基于 Redis 的分布式锁优缺点","slug":"基于-redis-的分布式锁优缺点","link":"#基于-redis-的分布式锁优缺点","children":[]},{"level":4,"title":"如何解决集群情况下分布式锁的可靠性","slug":"如何解决集群情况下分布式锁的可靠性","link":"#如何解决集群情况下分布式锁的可靠性","children":[]}]}]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":16.91,"words":5073},"filePathRelative":"MdNote_Public/01. DesignAndDevelop/Develop/02. Theory/Computer/03. 计算机系统 - 线性学习版/《小林coding_图解系列》/04. 图解Redis/01. 面试篇/09. 实战.md","excerpt":"\\n<h2>Redis 实战</h2>\\n<h3>延迟队列</h3>\\n<p>什么是延迟队列？</p>\\n<blockquote>\\n<p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：</p>\\n<ol>\\n<li>在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；</li>\\n<li>打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；</li>\\n<li>点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；</li>\\n</ol>\\n</blockquote>\\n<p>如何实现延迟队列？</p>\\n<blockquote>\\n<p>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。</p>\\n<p>使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。</p>\\n<p></p>\\n</blockquote>","autoDesc":true}');export{E as comp,R as data};
