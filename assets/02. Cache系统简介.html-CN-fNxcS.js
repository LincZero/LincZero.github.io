import{_ as a,e as l,g as c,o as h}from"./app-DPU1xou8.js";const i="/assets/Image00070-C5IVLnxu.jpg",t={};function o(n,e){return h(),l("div",null,e[0]||(e[0]=[c('<h1 id="cache系统简介" tabindex="-1"><a class="header-anchor" href="#cache系统简介"><span>Cache系统简介</span></a></h1><p>随着计算机行业的飞速发展，CPU的速度和内存的大小都发生了翻天覆地的变化。英特尔公司在1982年推出80286芯片的时候，处理器内部含有13.4万个晶体管，时钟频率只有6MHz，内部和外部数据总线只有16位，地址总线24位，可寻址内存大小16MB。</p><p>而英特尔公司在2014年推出的Haswell处理器的时候，处理器内部仅处理器本身就包含了17亿个晶体管，还不包括 Cache 和 GPU 这种复杂部件。时钟频率达到3.8GHz，数据总线和地址总线也都扩展到了64位，可以寻址的内存大小也已经开始以TB（1T=1024GB）计算。</p><p>在处理器速度不断增加的形势下，处理器处理数据的能力也得到大大提升。但是，数据是存储在内存中的，虽然随着 DDR2、DDR3、DDR4 的新技术不断推出，内存的吞吐率得到了大大提升，但是相对于处理器来讲，仍然非常慢。一般来讲，处理器要从内存中直接读取数据都要花大概几百个时钟周期，在这几百个时钟周期内，处理器除了等待什么也不能做。在这种环境下，才提出了 Cache 的概念，其目的就是为了匹配处理器和内存之间存在的巨大的速度鸿沟。</p><h2 id="cache的种类" tabindex="-1"><a class="header-anchor" href="#cache的种类"><span>Cache的种类</span></a></h2><h3 id="三级cache-简概" tabindex="-1"><a class="header-anchor" href="#三级cache-简概"><span>三级Cache - 简概</span></a></h3><p>一般来讲，Cache由三级组成，之所以对Cache进行分级，也是<strong>从成本和生产工艺的角度考虑</strong>的。一级（L1）最快，但是容量最小；三级（LLC，Last Level Cache）最慢，但是容量最大，在早期计算机系统中，这一级Cache也可以省略。不过在当今时代，大多数处理器都会包含这一级Cache。</p><blockquote><p>趣闻：在早期，第三级在主板而非处理器内部。</p><p>Cache 是一种 SRAM，在早期计算机系统中，一般一级和二级Cache集成在处理器内部，三级Cache集成在主板上，这样做的主要原因是生产工艺的问题，处理器内部能够集成的晶体管数目有限，而三级Cache又比较大，从而占用的晶体管数量较多。以英特尔最新的Haswell i7-5960X为例，一级Cache有32K，二级有512K，但是三级却有20M，在早期计算机系统中集成如此大的SRAM实在是很难做到。不过随着90nm、45nm、32nm以及22nm工艺的推出，处理器内部能够容纳更多的晶体管，所以三级Cache也慢慢集成到处理器内部了。</p></blockquote><h3 id="三级cache-示意图" tabindex="-1"><a class="header-anchor" href="#三级cache-示意图"><span>三级Cache - 示意图</span></a></h3><p>图2-4是一个简单的Cache系统逻辑示意图，可结合后面的详细说明来看</p><p>Cache系统示意图：</p><p><img src="'+i+'" alt="img" loading="lazy"></p><h3 id="三级cache-详细" tabindex="-1"><a class="header-anchor" href="#三级cache-详细"><span>三级Cache - 详细</span></a></h3><blockquote><h4 id="对比" tabindex="-1"><a class="header-anchor" href="#对比"><span>对比</span></a></h4></blockquote><ul><li>一级Cache <ul><li>一般<em>分为数据Cache和指令Cache</em>，数据Cache用来存储数据，而指令Cache用于存放指令</li><li>速度：这种Cache<em>速度最快</em>，一般处理器只需要<em>3~5个指令周期</em>就能访问到数据</li><li>容量：<em>成本高，容量小，一般都只有几十KB</em></li><li>多核：在多核处理器内部，每个处理器核心都拥有仅属于自己的一级Cache。</li></ul></li><li>二级Cache <ul><li>和一级Cache分为数据Cache和指令Cache不同，<em>数据和指令都无差别地存放在一起</em></li><li>速度：速度相比一级Cache慢一些，处理器大约需要<em>十几个处理器周期</em>才能访问到数据</li><li>容量：容量也相对来说大一些，一般有几百KB到几MB不等。</li><li>多核：在多核处理器内部，每个处理器核心都拥有仅属于自己的二级Cache</li></ul></li><li>三级Cache <ul><li>速度：速度更慢，处理器需要<em>几十个处理器周期</em>才能访问到数据</li><li>容量：容量更大，一般都有几MB到几十个MB</li><li>在多核处理器内部，三级Cache由所有的核心所共有。这样的共享方式，其实也带来一个问题，有的处理器可能会极大地占用三级Cache，导致其他处理器只能占用极小的容量，从而导致Cache不命中，性能下降。因此，英特尔公司推出了Intel ® CAT技术，确保有一个公平，或者说软件可配置的算法来控制每个核心可以用到的Cache大小。在此，本书就不再赘述。</li></ul></li></ul><blockquote><h4 id="按纬度对比" tabindex="-1"><a class="header-anchor" href="#按纬度对比"><span>按纬度对比</span></a></h4></blockquote><ul><li>多核 <ul><li>三级Cache是共享的</li><li>一二级Cache是每个核都有。这便导致了同一线程跨核会容易导致 cache 缓存的损失，所以DPDK才让你用亲和核</li></ul></li><li>速度 <ul><li><em>速度稳定</em>：对于各级Cache的访问时间，在英特尔的处理器上一直都保持着非常稳定，这里所谓的稳定，是指在不同频率、不同型号的英特尔处理器上，处理器访问这三级Cache所花费的指令周期数是相同的。请参照［Ref2-2］。</li><li><em>一级Cache：4个指令周期</em></li><li><em>二级Cache：12个指令周期</em></li><li><em>三级Cache：26~31个指令周期</em></li></ul></li></ul><h2 id="tlb-cache-translation-look-aside-buffer-翻译后援缓冲器" tabindex="-1"><a class="header-anchor" href="#tlb-cache-translation-look-aside-buffer-翻译后援缓冲器"><span>TLB Cache（Translation Look-aside Buffer，翻译后援缓冲器）</span></a></h2><p>除了上述的Cache种类之外，还包含一些其他类型，接下来的章节会接着介绍。</p><p>先说一下虚拟地址和分段分页技术：</p><blockquote><p>在早期计算机系统中，程序员都是直接访问物理地址进行编程，当程序出现错误时，整个系统都瘫痪掉；或者在多进程系统中，当一个进程出现问题，对属于另外一个进程的数据或者指令区域进行写操作，会导致另外一个进程崩溃。</p><p>因此，随着计算机技术的进步，虚拟地址和分段分页技术被提出来用来保护脆弱的软件系统。</p><ul><li>虚拟地址：软件使用虚拟地址访问内存，而处理器负责虚拟地址到物理地址的映射工作。</li><li>多级页表：为了完成映射工作，处理器采用多级页表来进行多次查找最终找到真正的物理地址。</li></ul><p>当处理器发现页表中找不到真正对应的物理地址时，就会发出一个异常，挂起寻址错误的进程，但是其他进程仍然可以正常工作。</p></blockquote><p>某些场景需要使用 TLB 而非 三级Cache</p><blockquote><p>页表也存储在内存中，处理器虽然可以利用三级Cache系统来缓存页表内容，但是相较另一种方案有两点劣势而不这样做 (后面会说)。</p><p>而是使用 <strong>TLB（Translation Look-aside Buffer）Cache</strong> 专门用于缓存内存中的页表项。</p><p>在实现上：TLB一般都采用<em>相连存储器或者按内容访问存储器（CAM，Content Addressable Memory）</em>。</p><p>三级Cache 相比 TLB 的两个劣势：</p><ol><li>访问页表过于频繁 <ul><li>处理器每当进行寻址操作都要进行一次映射工作，这使得处理器访问页表的频率非常得高，有可能一秒钟需要访问几万次。因此，即使Cache的命中率能够达到99%以上，也就是说不命中率有1%，那么不命中的概率每秒也有几百次，这会导致处理器在单位时间内访问内存（因为Cache没有命中，只能访问内存）的次数增多，降低了系统的性能。</li></ul></li><li>要多次访问多级页表才能获得物理地址 <ul><li>相连存储器使用虚拟地址进行搜索，直接返回对应的物理地址。相对于内存中的多级页表需要多次访问才能得到最终的物理地址，TLB查找无疑大大减少了处理器的开销。</li><li>如果需要的地址在TLB Cache中，即 <em>TLB命中</em>，相连存储器迅速返回结果，然后处理器用该物理地址访问内存，这样的查找操作也称为 ；</li><li>如果需要的地址不在TLB Cache中，即 <em>不命中</em>，处理器就需要到内存中访问多级页表，才能最终得到物理地址。</li></ul></li></ol></blockquote>',23)]))}const r=a(t,[["render",o],["__file","02. Cache系统简介.html.vue"]]),C=JSON.parse('{"path":"/MdNote_Public/01.%20DesignAndDevelop/Develop/02.%20Theory/Computer/03.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%20-%20%E4%B8%93%E9%A2%98%E6%88%96%E5%AD%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AD%97%E5%85%B8%E7%89%88/%E4%B8%8B%E5%B1%82%E7%9B%B8%E5%85%B3/Network/%E3%80%8ANFV%E7%9A%84%E5%9F%BA%E7%9F%B3_%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BADPDK%E3%80%8B/02.%20Cache%E5%92%8C%E5%86%85%E5%AD%98/02.%20Cache%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B.html","title":"Cache系统简介","lang":"zh-CN","frontmatter":{"description":"Cache系统简介 随着计算机行业的飞速发展，CPU的速度和内存的大小都发生了翻天覆地的变化。英特尔公司在1982年推出80286芯片的时候，处理器内部含有13.4万个晶体管，时钟频率只有6MHz，内部和外部数据总线只有16位，地址总线24位，可寻址内存大小16MB。 而英特尔公司在2014年推出的Haswell处理器的时候，处理器内部仅处理器本身就包...","head":[["meta",{"property":"og:url","content":"https://LincZero.github.io/MdNote_Public/01.%20DesignAndDevelop/Develop/02.%20Theory/Computer/03.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%20-%20%E4%B8%93%E9%A2%98%E6%88%96%E5%AD%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AD%97%E5%85%B8%E7%89%88/%E4%B8%8B%E5%B1%82%E7%9B%B8%E5%85%B3/Network/%E3%80%8ANFV%E7%9A%84%E5%9F%BA%E7%9F%B3_%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BADPDK%E3%80%8B/02.%20Cache%E5%92%8C%E5%86%85%E5%AD%98/02.%20Cache%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B.html"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"Cache系统简介"}],["meta",{"property":"og:description","content":"Cache系统简介 随着计算机行业的飞速发展，CPU的速度和内存的大小都发生了翻天覆地的变化。英特尔公司在1982年推出80286芯片的时候，处理器内部含有13.4万个晶体管，时钟频率只有6MHz，内部和外部数据总线只有16位，地址总线24位，可寻址内存大小16MB。 而英特尔公司在2014年推出的Haswell处理器的时候，处理器内部仅处理器本身就包..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Cache系统简介\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"git":{},"readingTime":{"minutes":7.02,"words":2105},"filePathRelative":"MdNote_Public/01. DesignAndDevelop/Develop/02. Theory/Computer/03. 计算机系统 - 专题或子系统的字典版/下层相关/Network/《NFV的基石_深入浅出DPDK》/02. Cache和内存/02. Cache系统简介.md","excerpt":"\\n<p>随着计算机行业的飞速发展，CPU的速度和内存的大小都发生了翻天覆地的变化。英特尔公司在1982年推出80286芯片的时候，处理器内部含有13.4万个晶体管，时钟频率只有6MHz，内部和外部数据总线只有16位，地址总线24位，可寻址内存大小16MB。</p>\\n<p>而英特尔公司在2014年推出的Haswell处理器的时候，处理器内部仅处理器本身就包含了17亿个晶体管，还不包括 Cache 和 GPU 这种复杂部件。时钟频率达到3.8GHz，数据总线和地址总线也都扩展到了64位，可以寻址的内存大小也已经开始以TB（1T=1024GB）计算。</p>\\n<p>在处理器速度不断增加的形势下，处理器处理数据的能力也得到大大提升。但是，数据是存储在内存中的，虽然随着 DDR2、DDR3、DDR4 的新技术不断推出，内存的吞吐率得到了大大提升，但是相对于处理器来讲，仍然非常慢。一般来讲，处理器要从内存中直接读取数据都要花大概几百个时钟周期，在这几百个时钟周期内，处理器除了等待什么也不能做。在这种环境下，才提出了 Cache 的概念，其目的就是为了匹配处理器和内存之间存在的巨大的速度鸿沟。</p>","autoDesc":true,"bioChainData":{"outlink":[],"backlink":[],"localMap":{"nodes":[{"id":"MdNote_Public/01. DesignAndDevelop/Develop/02. Theory/Computer/03. 计算机系统 - 专题或子系统的字典版/下层相关/Network/《NFV的基石_深入浅出DPDK》/02. Cache和内存/02. Cache系统简介.md","value":{"title":"02. Cache系统简介","path":"MdNote_Public/01. DesignAndDevelop/Develop/02. Theory/Computer/03. 计算机系统 - 专题或子系统的字典版/下层相关/Network/《NFV的基石_深入浅出DPDK》/02. Cache和内存/02. Cache系统简介.md","outlink":[],"backlink":[]}}],"links":[]}}}');export{r as comp,C as data};
