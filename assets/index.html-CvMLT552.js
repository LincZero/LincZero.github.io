import{_ as t,c as o,e as a,o as i}from"./app-_6RECMRt.js";const n="/assets/image_to_video-BhSvsZB0.webp",r="/assets/txt_to_image_to_video-CoYt3ZIY.webp",s={};function l(p,e){return i(),o("div",null,e[0]||(e[0]=[a('<h1 id="视频示例" tabindex="-1"><a class="header-anchor" href="#视频示例"><span>视频示例</span></a></h1><h2 id="图像转视频" tabindex="-1"><a class="header-anchor" href="#图像转视频"><span>图像转视频</span></a></h2><p>截至撰写本文时，有两个图像到视频检查点。以下是针对<a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/blob/main/svd.safetensors" target="_blank" rel="noopener noreferrer">生成 14 帧视频</a>和<a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt/blob/main/svd_xt.safetensors" target="_blank" rel="noopener noreferrer">25 帧视频</a>的官方检查点。将它们放在 ComfyUI/models/checkpoints 文件夹中。</p><p>使用图像转视频模型的最基本方法是给它一个初始图像，就像下面使用 14 帧模型的工作流程一样。您可以下载此 webp 动画图像并加载它或将其拖到<a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" rel="noopener noreferrer">ComfyUI</a>上以获取工作流程。</p><p><img src="'+n+'" alt="Example" loading="lazy"><a href="https://comfyanonymous.github.io/ComfyUI_examples/video/workflow_image_to_video.json" target="_blank" rel="noopener noreferrer">Json 格式的工作流</a></p><p>如果你想要精确的输入图像，你可以在<a href="https://comfyanonymous.github.io/ComfyUI_examples/unclip" target="_blank" rel="noopener noreferrer">unCLIP 示例页面上找到它</a></p><p>您还可以像在此工作流程中使用它们，该工作流程使用 SDXL 生成初始图像，然后将其传递给 25 帧模型：</p><p><img src="'+r+'" alt="Example" loading="lazy"><a href="https://comfyanonymous.github.io/ComfyUI_examples/video/workflow_txt_to_img_to_video.json" target="_blank" rel="noopener noreferrer">Json 格式的工作流</a></p><h4 id="一些参数的解释" tabindex="-1"><a class="header-anchor" href="#一些参数的解释"><span>一些参数的解释：</span></a></h4><ul><li>video_frames：要生成的视频帧的数量。</li><li>motion_bucket_id：数字越高，视频中的动作越多。</li><li>fps：fps 越高，视频的不流畅程度越低。</li><li>增强级别：添加到初始图像的噪声量，噪声级别越高，视频看起来就越不像初始图像。增加噪声级别可获得更多动感。</li><li>VideoLinearCFGGuidance：此节点稍微改进了这些视频模型的采样，它所做的是线性缩放不同帧之间的 cfg。在上面的示例中，第一帧的 cfg 为 1.0（节点中的 min_cfg），中间帧为 1.75，最后一帧为 2.5。（采样器中设置的 cfg）。这样，距离初始帧较远的帧会获得逐渐更高的 cfg。</li></ul>',10)]))}const c=t(s,[["render",l],["__file","index.html.vue"]]),d=JSON.parse('{"path":"/MdNote_Other/ComfyUI_examples/video/","title":"视频示例","lang":"zh-CN","frontmatter":{"description":"视频示例 图像转视频 截至撰写本文时，有两个图像到视频检查点。以下是针对生成 14 帧视频和25 帧视频的官方检查点。将它们放在 ComfyUI/models/checkpoints 文件夹中。 使用图像转视频模型的最基本方法是给它一个初始图像，就像下面使用 14 帧模型的工作流程一样。您可以下载此 webp 动画图像并加载它或将其拖到ComfyUI上...","head":[["meta",{"property":"og:url","content":"https://LincZero.github.io/MdNote_Other/ComfyUI_examples/video/"}],["meta",{"property":"og:site_name","content":"Linc 的小站"}],["meta",{"property":"og:title","content":"视频示例"}],["meta",{"property":"og:description","content":"视频示例 图像转视频 截至撰写本文时，有两个图像到视频检查点。以下是针对生成 14 帧视频和25 帧视频的官方检查点。将它们放在 ComfyUI/models/checkpoints 文件夹中。 使用图像转视频模型的最基本方法是给它一个初始图像，就像下面使用 14 帧模型的工作流程一样。您可以下载此 webp 动画图像并加载它或将其拖到ComfyUI上..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"视频示例\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LincZero\\",\\"url\\":\\"https://github.com/LincZero/\\"}]}"]]},"headers":[{"level":1,"title":"视频示例","slug":"视频示例","link":"#视频示例","children":[{"level":2,"title":"图像转视频","slug":"图像转视频","link":"#图像转视频","children":[{"level":4,"title":"一些参数的解释：","slug":"一些参数的解释","link":"#一些参数的解释","children":[]}]}]}],"git":{},"readingTime":{"minutes":1.39,"words":416},"filePathRelative":"MdNote_Other/ComfyUI_examples/video/README.md","excerpt":"\\n<h2>图像转视频</h2>\\n<p>截至撰写本文时，有两个图像到视频检查点。以下是针对<a href=\\"https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/blob/main/svd.safetensors\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">生成 14 帧视频</a>和<a href=\\"https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt/blob/main/svd_xt.safetensors\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">25 帧视频</a>的官方检查点。将它们放在 ComfyUI/models/checkpoints 文件夹中。</p>","autoDesc":true,"bioChainData":{"outlink":[],"backlink":[],"localMap":{"nodes":[{"id":"MdNote_Other/ComfyUI_examples/video/README.md","value":{"title":"ComfyUI_examples/","path":"MdNote_Other/ComfyUI_examples/video/README.md","outlink":[],"backlink":[]}}],"links":[]}}}');export{c as comp,d as data};
